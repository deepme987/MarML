{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfPPQ6ztJhv4"
   },
   "source": [
    "# TorchVision Instance Segmentation Finetuning Tutorial\n",
    "\n",
    "For this tutorial, we will be finetuning a pre-trained [Mask R-CNN](https://arxiv.org/abs/1703.06870) model in the [*Penn-Fudan Database for Pedestrian Detection and Segmentation*](https://www.cis.upenn.edu/~jshi/ped_html/). It contains 170 images with 345 instances of pedestrians, and we will use it to illustrate how to use the new features in torchvision in order to train an instance segmentation model on a custom dataset.\n",
    "\n",
    "First, we need to install `pycocotools`. This library will be used for computing the evaluation metrics following the COCO metric for intersection over union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBIoe_tHTQgV",
    "outputId": "eec9e0e0-c254-4394-c234-d49844a09308"
   },
   "outputs": [],
   "source": [
    "# !pip install cython\n",
    "# # Install pycocotools, the version by default in Colab\n",
    "# # has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
    "# !pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Sd4jlGp2eLm"
   },
   "source": [
    "## Defining the Dataset\n",
    "\n",
    "The [torchvision reference scripts for training object detection, instance segmentation and person keypoint detection](https://github.com/pytorch/vision/tree/v0.3.0/references/detection) allows for easily supporting adding new custom datasets.\n",
    "The dataset should inherit from the standard `torch.utils.data.Dataset` class, and implement `__len__` and `__getitem__`.\n",
    "\n",
    "The only specificity that we require is that the dataset `__getitem__` should return:\n",
    "\n",
    "* image: a PIL Image of size (H, W)\n",
    "* target: a dict containing the following fields\n",
    "    * `boxes` (`FloatTensor[N, 4]`): the coordinates of the `N` bounding boxes in `[x0, y0, x1, y1]` format, ranging from `0` to `W` and `0` to `H`\n",
    "    * `labels` (`Int64Tensor[N]`): the label for each bounding box\n",
    "    * `image_id` (`Int64Tensor[1]`): an image identifier. It should be unique between all the images in the dataset, and is used during evaluation\n",
    "    * `area` (`Tensor[N]`): The area of the bounding box. This is used during evaluation with the COCO metric, to separate the metric scores between small, medium and large boxes.\n",
    "    * `iscrowd` (`UInt8Tensor[N]`): instances with `iscrowd=True` will be ignored during evaluation.\n",
    "    * (optionally) `masks` (`UInt8Tensor[N, H, W]`): The segmentation masks for each one of the objects\n",
    "    * (optionally) `keypoints` (`FloatTensor[N, K, 3]`): For each one of the `N` objects, it contains the `K` keypoints in `[x, y, visibility]` format, defining the object. `visibility=0` means that the keypoint is not visible. Note that for data augmentation, the notion of flipping a keypoint is dependent on the data representation, and you should probably adapt `references/detection/transforms.py` for your new keypoint representation\n",
    "\n",
    "If your model returns the above methods, they will make it work for both training and evaluation, and will use the evaluation scripts from pycocotools.\n",
    "\n",
    "\n",
    "One note on the labels. The model considers class 0 as background. If your dataset does not contain the background class, you should not have 0 in your labels. For example, assuming you have just two classes, cat and dog, you can define 1 (not 0) to represent cats and 2 to represent dogs. So, for instance, if one of the images has both classes, your labels tensor should look like [1,2].\n",
    "\n",
    "Additionally, if you want to use aspect ratio grouping during training (so that each batch only contains images with similar aspect ratio), then it is recommended to also implement a `get_height_and_width` method, which returns the height and the width of the image. If this method is not provided, we query all elements of the dataset via `__getitem__` , which loads the image in memory and is slower than if a custom method is provided.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX0rqK-A3Nbl"
   },
   "source": [
    "### Writing a custom dataset for Penn-Fudan\n",
    "\n",
    "Let's write a dataset for the Penn-Fudan dataset.\n",
    "\n",
    "First, let's download and extract the data, present in a zip file at https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mTgWtixZTs3X"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "\n",
    "class SMDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, yolo_dir, transform=None, target_transform=None):\n",
    "        self.yolo_dir = yolo_dir\n",
    "        self.images_dir = glob.glob(yolo_dir + \"*.jpg\")\n",
    "        self.labels_dir = glob.glob(yolo_dir + \"*.txt\")\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_dir)\n",
    "    \n",
    "    def read_yolo(self, label_path, height, width):\n",
    "        with open(label_path, 'r') as f:\n",
    "            data = f.readlines()\n",
    "        data = [dat.split() for dat in data]\n",
    "        data = np.array(data, dtype=float)\n",
    "        labels = data[:, 1].astype('int64') # 0 - moving; 1 - category; 2 - distance\n",
    "#         labels = data[:, :3].astype('int64') # 0 - moving; 1 - category; 2 - distance\n",
    "        bboxes = data[:, -4:]\n",
    "        bboxes[:, 0] = bboxes[:, 0] - bboxes[:, 2] / 2\n",
    "        bboxes[:, 1] = bboxes[:, 1] - bboxes[:, 3] / 2\n",
    "        bboxes[:, 2] = bboxes[:, 0] + bboxes[:, 2]\n",
    "        bboxes[:, 3] = bboxes[:, 1] + bboxes[:, 3]\n",
    "        \n",
    "        return torch.from_numpy(labels), torch.from_numpy(bboxes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images_dir[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        height, width = image.size\n",
    "        labels, bboxes = self.read_yolo(self.labels_dir[idx], height, width)\n",
    "\n",
    "        target = dict()\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"boxes\"] = bboxes\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6f3ZOTJ4Km9"
   },
   "source": [
    "That's all for the dataset. Let's see how the outputs are structured for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEARO4B_ye0s",
    "outputId": "bc58a1cf-84be-4ef8-9cb1-ef489bd26ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=1920x1080 at 0x1A656143E88>,\n",
       " {'labels': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3]),\n",
       "  'boxes': tensor([[5.2083e-04, 2.5926e-01, 2.4479e-02, 3.5556e-01],\n",
       "          [1.4063e-02, 2.7315e-01, 5.9375e-02, 3.2870e-01],\n",
       "          [9.7656e-02, 2.8148e-01, 2.1901e-01, 3.1944e-01],\n",
       "          [7.8906e-02, 2.9259e-01, 1.0911e-01, 3.1759e-01],\n",
       "          [2.0651e-01, 2.6944e-01, 2.4870e-01, 3.3519e-01],\n",
       "          [3.4818e-01, 2.7083e-01, 4.1432e-01, 3.3657e-01],\n",
       "          [3.8229e-01, 2.7593e-01, 4.0833e-01, 3.3148e-01],\n",
       "          [3.9714e-01, 2.6991e-01, 5.7734e-01, 3.3843e-01],\n",
       "          [2.1406e-01, 2.4815e-01, 3.8385e-01, 4.6481e-01]], dtype=torch.float64)})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = SMDDataset('SMD/NIR/data_yolo/')\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWOhcsir9Ahx"
   },
   "source": [
    "So we can see that by default, the dataset returns a `PIL.Image` and a dictionary\n",
    "containing several fields, including `boxes`, `labels` and `masks`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoAEkUgn4uEq"
   },
   "source": [
    "## Defining your model\n",
    "\n",
    "In this tutorial, we will be using [Mask R-CNN](https://arxiv.org/abs/1703.06870), which is based on top of [Faster R-CNN](https://arxiv.org/abs/1506.01497). Faster R-CNN is a model that predicts both bounding boxes and class scores for potential objects in the image.\n",
    "\n",
    "![Faster R-CNN](https://raw.githubusercontent.com/pytorch/vision/temp-tutorial/tutorials/tv_image03.png)\n",
    "\n",
    "Mask R-CNN adds an extra branch into Faster R-CNN, which also predicts segmentation masks for each instance.\n",
    "\n",
    "![Mask R-CNN](https://raw.githubusercontent.com/pytorch/vision/temp-tutorial/tutorials/tv_image04.png)\n",
    "\n",
    "There are two common situations where one might want to modify one of the available models in torchvision modelzoo.\n",
    "The first is when we want to start from a pre-trained model, and just finetune the last layer. The other is when we want to replace the backbone of the model with a different one (for faster predictions, for example).\n",
    "\n",
    "Let's go see how we would do one or another in the following sections.\n",
    "\n",
    "\n",
    "### 1 - Finetuning from a pretrained model\n",
    "\n",
    "Let's suppose that you want to start from a model pre-trained on COCO and want to finetune it for your particular classes. Here is a possible way of doing it:\n",
    "```\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
    "```\n",
    "\n",
    "### 2 - Modifying the model to add a different backbone\n",
    "\n",
    "Another common situation arises when the user wants to replace the backbone of a detection\n",
    "model with a different one. For example, the current default backbone (ResNet-50) might be too big for some applications, and smaller models might be necessary.\n",
    "\n",
    "Here is how we would go into leveraging the functions provided by torchvision to modify a backbone.\n",
    "\n",
    "```\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "# load a pre-trained model for classification and return\n",
    "# only the features\n",
    "backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "# FasterRCNN needs to know the number of\n",
    "# output channels in a backbone. For mobilenet_v2, it's 1280\n",
    "# so we need to add it here\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "# let's make the RPN generate 5 x 3 anchors per spatial\n",
    "# location, with 5 different sizes and 3 different aspect\n",
    "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
    "# map could potentially have different sizes and\n",
    "# aspect ratios \n",
    "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                   aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "# let's define what are the feature maps that we will\n",
    "# use to perform the region of interest cropping, as well as\n",
    "# the size of the crop after rescaling.\n",
    "# if your backbone returns a Tensor, featmap_names is expected to\n",
    "# be [0]. More generally, the backbone should return an\n",
    "# OrderedDict[Tensor], and in featmap_names you can choose which\n",
    "# feature maps to use.\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=[0],\n",
    "                                                output_size=7,\n",
    "                                                sampling_ratio=2)\n",
    "\n",
    "# put the pieces together inside a FasterRCNN model\n",
    "model = FasterRCNN(backbone,\n",
    "                   num_classes=2,\n",
    "                   rpn_anchor_generator=anchor_generator,\n",
    "                   box_roi_pool=roi_pooler)\n",
    "```\n",
    "\n",
    "### An Instance segmentation model for PennFudan Dataset\n",
    "\n",
    "In our case, we want to fine-tune from a pre-trained model, given that our dataset is very small. So we will be following approach number 1.\n",
    "\n",
    "Here we want to also compute the instance segmentation masks, so we will be using Mask R-CNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WXLwePV5ieP"
   },
   "source": [
    "That's it, this will make model be ready to be trained and evaluated on our custom dataset.\n",
    "\n",
    "## Training and evaluation functions\n",
    "\n",
    "In `references/detection/,` we have a number of helper functions to simplify training and evaluating detection models.\n",
    "Here, we will use `references/detection/engine.py`, `references/detection/utils.py` and `references/detection/transforms.py`.\n",
    "\n",
    "Let's copy those files (and their dependencies) in here so that they are available in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u9e_pdv54nG"
   },
   "source": [
    "\n",
    "\n",
    "Let's write some helper functions for data augmentation / transformation, which leverages the functions in `refereces/detection` that we have just copied:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l79ivkwKy357"
   },
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "from torchvision import transforms as T\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_frcnn_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovjC81FZfWat"
   },
   "source": [
    "#### Testing forward() method \n",
    "\n",
    "Before iterating over the dataset, it’s good to see what the model expects during training and inference time on sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "11ef8a23d72b4d07a96eb606a8fa7d2d",
      "681f345b760e498ab2dfc5fcf07ec6e3",
      "c46939cc3d464b72827c194b2e01e85f",
      "a660849e2de94da3ac03810cdece69b7",
      "a1c7b3c5d9084c659634d577dc56dcc2",
      "9bceb871ca384508bc40bbbbda78a2b0",
      "3dd5d7a58a9d4b15817aeee7d13a79f9",
      "e1d6e629955149b7b07c1c20460c205c",
      "4308ed7944ee4ef596b4ebfbc3a3213b",
      "234b27f5e6374a62a8686fe7d32fddf7",
      "74e7d3cdc9a24f0ca3684250da665f34"
     ]
    },
    "id": "6-NFR--2fXV3",
    "outputId": "1a079bbf-e7a5-4048-b395-5f21269a2775"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "dataset = SMDDataset('SMD/NIR/data_yolo/', get_transform(train=True))\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=0,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "# For Training\n",
    "images,targets = next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images,targets)   # Returns losses and detections\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)           # Returns predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YFJGJxk6XEs"
   },
   "source": [
    "### Putting everything together\n",
    "\n",
    "We now have the dataset class, the models and the data transforms. Let's instantiate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5dGaIezze3y",
    "outputId": "94dc2ef3-8217-44db-832c-bd514f6c3880"
   },
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "\n",
    "data = SMDDataset(\"SMD/NIR/data_yolo/\", transform=get_transform(True))\n",
    "\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "dataset, dataset_test = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=0,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5yvZUprj4ZN"
   },
   "source": [
    "Now let's instantiate the model and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "4d28be85396240e0ac7c45b7d6ae06d3",
      "493adee22cb74a8a96183c9db4c5c56c",
      "eb4c4da938104534901663544b792d29",
      "dbd1290d275f4a21a01bc3a1643ea43a",
      "59d43ab0fe5c4fb3a87697219545cc15",
      "a33eeab89ffd48ddb69854bb4dbd88d8",
      "37c6d9f45f9d441895ed8610b3b5742b",
      "36db4a67e2464098bcb5b3dd3a54b843",
      "afe2458d0b5a4cf49c46c4b462a84fe9",
      "185aeb8e45074993bff2dfe7ec7fddd8",
      "1135b1ce2cd546469cf17372f4e54d0e"
     ]
    },
    "id": "zoenkCj18C4h",
    "outputId": "25d445bb-b0d6-4d52-d288-f1a759832c7f"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 11\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_frcnn_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAd56lt4kDxc"
   },
   "source": [
    "And now let's train the model for 10 epochs, evaluating at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "at-h4OWK0aoc",
    "outputId": "d3699771-b244-4da7-d613-31e9f78fe1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [   0/4489]  eta: 1:46:26  lr: 0.000000  loss: 0.5433 (0.5433)  loss_classifier: 0.1577 (0.1577)  loss_box_reg: 0.0099 (0.0099)  loss_objectness: 0.0904 (0.0904)  loss_rpn_box_reg: 0.2853 (0.2853)  time: 1.4228  data: 0.1416  max mem: 2501\n",
      "Epoch: [0]  [  10/4489]  eta: 1:39:04  lr: 0.000003  loss: 0.5805 (0.6083)  loss_classifier: 0.1456 (0.1652)  loss_box_reg: 0.0104 (0.0115)  loss_objectness: 0.1170 (0.1093)  loss_rpn_box_reg: 0.3052 (0.3223)  time: 1.3271  data: 0.1579  max mem: 2501\n",
      "Epoch: [0]  [  20/4489]  eta: 1:36:46  lr: 0.000005  loss: 0.5805 (0.6033)  loss_classifier: 0.1379 (0.1628)  loss_box_reg: 0.0104 (0.0106)  loss_objectness: 0.1126 (0.1112)  loss_rpn_box_reg: 0.3054 (0.3186)  time: 1.2932  data: 0.1389  max mem: 2501\n",
      "Epoch: [0]  [  30/4489]  eta: 1:35:52  lr: 0.000007  loss: 0.5764 (0.6009)  loss_classifier: 0.1342 (0.1606)  loss_box_reg: 0.0070 (0.0097)  loss_objectness: 0.0945 (0.1113)  loss_rpn_box_reg: 0.3100 (0.3192)  time: 1.2698  data: 0.1192  max mem: 2501\n",
      "Epoch: [0]  [  40/4489]  eta: 1:34:48  lr: 0.000009  loss: 0.6024 (0.5990)  loss_classifier: 0.1597 (0.1638)  loss_box_reg: 0.0078 (0.0093)  loss_objectness: 0.0909 (0.1071)  loss_rpn_box_reg: 0.3048 (0.3188)  time: 1.2568  data: 0.1110  max mem: 2501\n",
      "Epoch: [0]  [  50/4489]  eta: 1:33:21  lr: 0.000011  loss: 0.6051 (0.5912)  loss_classifier: 0.1580 (0.1614)  loss_box_reg: 0.0078 (0.0090)  loss_objectness: 0.0923 (0.1044)  loss_rpn_box_reg: 0.3026 (0.3164)  time: 1.2182  data: 0.0921  max mem: 2501\n",
      "Epoch: [0]  [  60/4489]  eta: 1:32:23  lr: 0.000013  loss: 0.5521 (0.5884)  loss_classifier: 0.1525 (0.1624)  loss_box_reg: 0.0073 (0.0089)  loss_objectness: 0.0925 (0.1016)  loss_rpn_box_reg: 0.2862 (0.3155)  time: 1.1961  data: 0.0835  max mem: 2501\n",
      "Epoch: [0]  [  70/4489]  eta: 1:31:37  lr: 0.000015  loss: 0.5294 (0.5763)  loss_classifier: 0.1465 (0.1578)  loss_box_reg: 0.0072 (0.0087)  loss_objectness: 0.0848 (0.0979)  loss_rpn_box_reg: 0.2851 (0.3118)  time: 1.1982  data: 0.0856  max mem: 2501\n",
      "Epoch: [0]  [  80/4489]  eta: 1:30:58  lr: 0.000017  loss: 0.5247 (0.5740)  loss_classifier: 0.1461 (0.1579)  loss_box_reg: 0.0069 (0.0084)  loss_objectness: 0.0848 (0.0968)  loss_rpn_box_reg: 0.2889 (0.3108)  time: 1.1969  data: 0.0847  max mem: 2501\n",
      "Epoch: [0]  [  90/4489]  eta: 1:30:25  lr: 0.000019  loss: 0.4801 (0.5594)  loss_classifier: 0.1128 (0.1516)  loss_box_reg: 0.0049 (0.0079)  loss_objectness: 0.0649 (0.0916)  loss_rpn_box_reg: 0.2941 (0.3084)  time: 1.1951  data: 0.0836  max mem: 2501\n",
      "Epoch: [0]  [ 100/4489]  eta: 1:29:56  lr: 0.000021  loss: 0.4499 (0.5519)  loss_classifier: 0.1143 (0.1499)  loss_box_reg: 0.0050 (0.0078)  loss_objectness: 0.0523 (0.0881)  loss_rpn_box_reg: 0.2815 (0.3062)  time: 1.1955  data: 0.0847  max mem: 2501\n",
      "Epoch: [0]  [ 110/4489]  eta: 1:29:32  lr: 0.000023  loss: 0.4675 (0.5461)  loss_classifier: 0.1387 (0.1504)  loss_box_reg: 0.0068 (0.0078)  loss_objectness: 0.0482 (0.0838)  loss_rpn_box_reg: 0.2764 (0.3041)  time: 1.1983  data: 0.0854  max mem: 2501\n",
      "Epoch: [0]  [ 120/4489]  eta: 1:29:12  lr: 0.000026  loss: 0.4230 (0.5340)  loss_classifier: 0.1299 (0.1468)  loss_box_reg: 0.0059 (0.0075)  loss_objectness: 0.0331 (0.0796)  loss_rpn_box_reg: 0.2616 (0.3000)  time: 1.2016  data: 0.0883  max mem: 2501\n",
      "Epoch: [0]  [ 130/4489]  eta: 1:28:56  lr: 0.000028  loss: 0.3983 (0.5246)  loss_classifier: 0.1110 (0.1441)  loss_box_reg: 0.0036 (0.0073)  loss_objectness: 0.0260 (0.0757)  loss_rpn_box_reg: 0.2575 (0.2975)  time: 1.2098  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [ 140/4489]  eta: 1:28:40  lr: 0.000030  loss: 0.3954 (0.5153)  loss_classifier: 0.1110 (0.1419)  loss_box_reg: 0.0028 (0.0070)  loss_objectness: 0.0260 (0.0719)  loss_rpn_box_reg: 0.2475 (0.2944)  time: 1.2136  data: 0.0947  max mem: 2501\n",
      "Epoch: [0]  [ 150/4489]  eta: 1:28:25  lr: 0.000032  loss: 0.3734 (0.5077)  loss_classifier: 0.1023 (0.1397)  loss_box_reg: 0.0037 (0.0068)  loss_objectness: 0.0257 (0.0690)  loss_rpn_box_reg: 0.2475 (0.2921)  time: 1.2119  data: 0.0931  max mem: 2501\n",
      "Epoch: [0]  [ 160/4489]  eta: 1:28:11  lr: 0.000034  loss: 0.3828 (0.5007)  loss_classifier: 0.1038 (0.1377)  loss_box_reg: 0.0037 (0.0067)  loss_objectness: 0.0209 (0.0659)  loss_rpn_box_reg: 0.2599 (0.2905)  time: 1.2154  data: 0.0955  max mem: 2501\n",
      "Epoch: [0]  [ 170/4489]  eta: 1:27:58  lr: 0.000036  loss: 0.3677 (0.4930)  loss_classifier: 0.0974 (0.1346)  loss_box_reg: 0.0034 (0.0065)  loss_objectness: 0.0151 (0.0629)  loss_rpn_box_reg: 0.2627 (0.2890)  time: 1.2186  data: 0.0985  max mem: 2501\n",
      "Epoch: [0]  [ 180/4489]  eta: 1:27:43  lr: 0.000038  loss: 0.3491 (0.4856)  loss_classifier: 0.0685 (0.1315)  loss_box_reg: 0.0035 (0.0063)  loss_objectness: 0.0152 (0.0606)  loss_rpn_box_reg: 0.2599 (0.2872)  time: 1.2146  data: 0.0968  max mem: 2501\n",
      "Epoch: [0]  [ 190/4489]  eta: 1:27:29  lr: 0.000040  loss: 0.3487 (0.4784)  loss_classifier: 0.0760 (0.1291)  loss_box_reg: 0.0040 (0.0062)  loss_objectness: 0.0153 (0.0582)  loss_rpn_box_reg: 0.2413 (0.2849)  time: 1.2124  data: 0.0946  max mem: 2501\n",
      "Epoch: [0]  [ 200/4489]  eta: 1:29:07  lr: 0.000042  loss: 0.3307 (0.4713)  loss_classifier: 0.0750 (0.1269)  loss_box_reg: 0.0039 (0.0060)  loss_objectness: 0.0120 (0.0558)  loss_rpn_box_reg: 0.2333 (0.2826)  time: 1.4746  data: 0.0947  max mem: 2501\n",
      "Epoch: [0]  [ 210/4489]  eta: 1:38:02  lr: 0.000044  loss: 0.3250 (0.4638)  loss_classifier: 0.0778 (0.1244)  loss_box_reg: 0.0025 (0.0059)  loss_objectness: 0.0099 (0.0538)  loss_rpn_box_reg: 0.2266 (0.2797)  time: 2.8403  data: 0.0986  max mem: 2501\n",
      "Epoch: [0]  [ 220/4489]  eta: 1:46:02  lr: 0.000047  loss: 0.3041 (0.4567)  loss_classifier: 0.0773 (0.1220)  loss_box_reg: 0.0025 (0.0058)  loss_objectness: 0.0117 (0.0519)  loss_rpn_box_reg: 0.2171 (0.2771)  time: 3.9396  data: 0.0975  max mem: 2501\n",
      "Epoch: [0]  [ 230/4489]  eta: 1:53:18  lr: 0.000049  loss: 0.2996 (0.4503)  loss_classifier: 0.0688 (0.1199)  loss_box_reg: 0.0025 (0.0057)  loss_objectness: 0.0100 (0.0500)  loss_rpn_box_reg: 0.2171 (0.2748)  time: 3.9347  data: 0.0947  max mem: 2501\n",
      "Epoch: [0]  [ 240/4489]  eta: 1:59:54  lr: 0.000051  loss: 0.2912 (0.4435)  loss_classifier: 0.0591 (0.1173)  loss_box_reg: 0.0025 (0.0055)  loss_objectness: 0.0093 (0.0484)  loss_rpn_box_reg: 0.2156 (0.2722)  time: 3.9334  data: 0.0967  max mem: 2501\n",
      "Epoch: [0]  [ 250/4489]  eta: 2:05:56  lr: 0.000053  loss: 0.2867 (0.4369)  loss_classifier: 0.0607 (0.1156)  loss_box_reg: 0.0020 (0.0054)  loss_objectness: 0.0099 (0.0469)  loss_rpn_box_reg: 0.2062 (0.2690)  time: 3.9359  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [ 260/4489]  eta: 2:11:27  lr: 0.000055  loss: 0.2544 (0.4303)  loss_classifier: 0.0628 (0.1135)  loss_box_reg: 0.0020 (0.0053)  loss_objectness: 0.0106 (0.0456)  loss_rpn_box_reg: 0.1830 (0.2659)  time: 3.9385  data: 0.0927  max mem: 2501\n",
      "Epoch: [0]  [ 270/4489]  eta: 2:16:32  lr: 0.000057  loss: 0.2569 (0.4248)  loss_classifier: 0.0577 (0.1116)  loss_box_reg: 0.0010 (0.0051)  loss_objectness: 0.0084 (0.0442)  loss_rpn_box_reg: 0.1959 (0.2638)  time: 3.9371  data: 0.0939  max mem: 2501\n",
      "Epoch: [0]  [ 280/4489]  eta: 2:21:13  lr: 0.000059  loss: 0.2796 (0.4203)  loss_classifier: 0.0509 (0.1094)  loss_box_reg: 0.0008 (0.0050)  loss_objectness: 0.0063 (0.0430)  loss_rpn_box_reg: 0.2088 (0.2629)  time: 3.9450  data: 0.1052  max mem: 2501\n",
      "Epoch: [0]  [ 290/4489]  eta: 2:25:29  lr: 0.000061  loss: 0.2455 (0.4138)  loss_classifier: 0.0419 (0.1072)  loss_box_reg: 0.0007 (0.0049)  loss_objectness: 0.0063 (0.0419)  loss_rpn_box_reg: 0.1927 (0.2599)  time: 3.9391  data: 0.1065  max mem: 2501\n",
      "Epoch: [0]  [ 300/4489]  eta: 2:29:26  lr: 0.000063  loss: 0.2287 (0.4082)  loss_classifier: 0.0389 (0.1052)  loss_box_reg: 0.0004 (0.0047)  loss_objectness: 0.0063 (0.0407)  loss_rpn_box_reg: 0.1755 (0.2575)  time: 3.9274  data: 0.0953  max mem: 2501\n",
      "Epoch: [0]  [ 310/4489]  eta: 2:33:06  lr: 0.000065  loss: 0.2485 (0.4033)  loss_classifier: 0.0525 (0.1036)  loss_box_reg: 0.0003 (0.0046)  loss_objectness: 0.0053 (0.0396)  loss_rpn_box_reg: 0.1909 (0.2556)  time: 3.9324  data: 0.0934  max mem: 2501\n",
      "Epoch: [0]  [ 320/4489]  eta: 2:36:30  lr: 0.000067  loss: 0.2523 (0.3983)  loss_classifier: 0.0525 (0.1019)  loss_box_reg: 0.0002 (0.0045)  loss_objectness: 0.0049 (0.0386)  loss_rpn_box_reg: 0.1874 (0.2533)  time: 3.9399  data: 0.0957  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 330/4489]  eta: 2:39:39  lr: 0.000070  loss: 0.2280 (0.3937)  loss_classifier: 0.0494 (0.1003)  loss_box_reg: 0.0013 (0.0044)  loss_objectness: 0.0040 (0.0376)  loss_rpn_box_reg: 0.1673 (0.2514)  time: 3.9377  data: 0.0966  max mem: 2501\n",
      "Epoch: [0]  [ 340/4489]  eta: 2:42:33  lr: 0.000072  loss: 0.2118 (0.3880)  loss_classifier: 0.0423 (0.0986)  loss_box_reg: 0.0013 (0.0043)  loss_objectness: 0.0033 (0.0366)  loss_rpn_box_reg: 0.1622 (0.2485)  time: 3.9297  data: 0.0959  max mem: 2501\n",
      "Epoch: [0]  [ 350/4489]  eta: 2:47:19  lr: 0.000074  loss: 0.1983 (0.3832)  loss_classifier: 0.0395 (0.0970)  loss_box_reg: 0.0003 (0.0042)  loss_objectness: 0.0029 (0.0357)  loss_rpn_box_reg: 0.1527 (0.2462)  time: 4.4502  data: 0.0935  max mem: 2501\n",
      "Epoch: [0]  [ 360/4489]  eta: 2:49:39  lr: 0.000076  loss: 0.1984 (0.3786)  loss_classifier: 0.0357 (0.0954)  loss_box_reg: 0.0001 (0.0042)  loss_objectness: 0.0029 (0.0350)  loss_rpn_box_reg: 0.1534 (0.2441)  time: 4.4152  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [ 370/4489]  eta: 2:51:48  lr: 0.000078  loss: 0.1922 (0.3734)  loss_classifier: 0.0348 (0.0938)  loss_box_reg: 0.0003 (0.0041)  loss_objectness: 0.0049 (0.0341)  loss_rpn_box_reg: 0.1447 (0.2414)  time: 3.8563  data: 0.0959  max mem: 2501\n",
      "Epoch: [0]  [ 380/4489]  eta: 2:53:50  lr: 0.000080  loss: 0.1893 (0.3691)  loss_classifier: 0.0362 (0.0923)  loss_box_reg: 0.0003 (0.0040)  loss_objectness: 0.0031 (0.0334)  loss_rpn_box_reg: 0.1410 (0.2394)  time: 3.8596  data: 0.0949  max mem: 2501\n",
      "Epoch: [0]  [ 390/4489]  eta: 2:55:44  lr: 0.000082  loss: 0.1888 (0.3644)  loss_classifier: 0.0329 (0.0909)  loss_box_reg: 0.0001 (0.0039)  loss_objectness: 0.0031 (0.0326)  loss_rpn_box_reg: 0.1362 (0.2370)  time: 3.8641  data: 0.0948  max mem: 2501\n",
      "Epoch: [0]  [ 400/4489]  eta: 2:57:30  lr: 0.000084  loss: 0.1992 (0.3611)  loss_classifier: 0.0329 (0.0896)  loss_box_reg: 0.0001 (0.0038)  loss_objectness: 0.0034 (0.0320)  loss_rpn_box_reg: 0.1596 (0.2357)  time: 3.8663  data: 0.0948  max mem: 2501\n",
      "Epoch: [0]  [ 410/4489]  eta: 2:59:09  lr: 0.000086  loss: 0.2006 (0.3570)  loss_classifier: 0.0346 (0.0883)  loss_box_reg: 0.0002 (0.0037)  loss_objectness: 0.0028 (0.0313)  loss_rpn_box_reg: 0.1632 (0.2337)  time: 3.8637  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [ 420/4489]  eta: 3:00:41  lr: 0.000088  loss: 0.1790 (0.3529)  loss_classifier: 0.0346 (0.0871)  loss_box_reg: 0.0007 (0.0037)  loss_objectness: 0.0029 (0.0306)  loss_rpn_box_reg: 0.1380 (0.2315)  time: 3.8645  data: 0.0964  max mem: 2501\n",
      "Epoch: [0]  [ 430/4489]  eta: 3:02:07  lr: 0.000091  loss: 0.1807 (0.3495)  loss_classifier: 0.0325 (0.0859)  loss_box_reg: 0.0003 (0.0036)  loss_objectness: 0.0030 (0.0300)  loss_rpn_box_reg: 0.1378 (0.2300)  time: 3.8632  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [ 440/4489]  eta: 3:03:28  lr: 0.000093  loss: 0.1843 (0.3461)  loss_classifier: 0.0278 (0.0846)  loss_box_reg: 0.0001 (0.0036)  loss_objectness: 0.0019 (0.0294)  loss_rpn_box_reg: 0.1512 (0.2284)  time: 3.8628  data: 0.0958  max mem: 2501\n",
      "Epoch: [0]  [ 450/4489]  eta: 3:04:43  lr: 0.000095  loss: 0.1937 (0.3427)  loss_classifier: 0.0278 (0.0835)  loss_box_reg: 0.0001 (0.0035)  loss_objectness: 0.0016 (0.0289)  loss_rpn_box_reg: 0.1571 (0.2269)  time: 3.8622  data: 0.0953  max mem: 2501\n",
      "Epoch: [0]  [ 460/4489]  eta: 3:05:52  lr: 0.000097  loss: 0.1812 (0.3396)  loss_classifier: 0.0289 (0.0824)  loss_box_reg: 0.0003 (0.0034)  loss_objectness: 0.0013 (0.0283)  loss_rpn_box_reg: 0.1512 (0.2255)  time: 3.8546  data: 0.0932  max mem: 2501\n",
      "Epoch: [0]  [ 470/4489]  eta: 3:06:58  lr: 0.000099  loss: 0.1845 (0.3369)  loss_classifier: 0.0310 (0.0814)  loss_box_reg: 0.0011 (0.0034)  loss_objectness: 0.0013 (0.0278)  loss_rpn_box_reg: 0.1530 (0.2243)  time: 3.8578  data: 0.0945  max mem: 2501\n",
      "Epoch: [0]  [ 480/4489]  eta: 3:07:59  lr: 0.000101  loss: 0.1664 (0.3329)  loss_classifier: 0.0301 (0.0804)  loss_box_reg: 0.0008 (0.0033)  loss_objectness: 0.0020 (0.0273)  loss_rpn_box_reg: 0.1283 (0.2219)  time: 3.8619  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [ 490/4489]  eta: 3:08:56  lr: 0.000103  loss: 0.1598 (0.3299)  loss_classifier: 0.0303 (0.0794)  loss_box_reg: 0.0001 (0.0033)  loss_objectness: 0.0015 (0.0267)  loss_rpn_box_reg: 0.1138 (0.2205)  time: 3.8599  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [ 500/4489]  eta: 3:09:50  lr: 0.000105  loss: 0.1903 (0.3271)  loss_classifier: 0.0299 (0.0784)  loss_box_reg: 0.0002 (0.0032)  loss_objectness: 0.0025 (0.0263)  loss_rpn_box_reg: 0.1532 (0.2191)  time: 3.8591  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [ 510/4489]  eta: 3:10:40  lr: 0.000107  loss: 0.1711 (0.3241)  loss_classifier: 0.0290 (0.0776)  loss_box_reg: 0.0002 (0.0032)  loss_objectness: 0.0035 (0.0259)  loss_rpn_box_reg: 0.1252 (0.2175)  time: 3.8647  data: 0.0969  max mem: 2501\n",
      "Epoch: [0]  [ 520/4489]  eta: 3:11:26  lr: 0.000109  loss: 0.1444 (0.3213)  loss_classifier: 0.0292 (0.0767)  loss_box_reg: 0.0002 (0.0032)  loss_objectness: 0.0027 (0.0255)  loss_rpn_box_reg: 0.1079 (0.2160)  time: 3.8636  data: 0.0955  max mem: 2501\n",
      "Epoch: [0]  [ 530/4489]  eta: 3:12:12  lr: 0.000111  loss: 0.1605 (0.3185)  loss_classifier: 0.0261 (0.0758)  loss_box_reg: 0.0003 (0.0031)  loss_objectness: 0.0027 (0.0251)  loss_rpn_box_reg: 0.1302 (0.2146)  time: 3.8750  data: 0.1070  max mem: 2501\n",
      "Epoch: [0]  [ 540/4489]  eta: 3:12:52  lr: 0.000114  loss: 0.1605 (0.3160)  loss_classifier: 0.0261 (0.0749)  loss_box_reg: 0.0007 (0.0031)  loss_objectness: 0.0019 (0.0247)  loss_rpn_box_reg: 0.1297 (0.2133)  time: 3.8794  data: 0.1077  max mem: 2501\n",
      "Epoch: [0]  [ 550/4489]  eta: 3:13:30  lr: 0.000116  loss: 0.1615 (0.3132)  loss_classifier: 0.0295 (0.0741)  loss_box_reg: 0.0003 (0.0030)  loss_objectness: 0.0015 (0.0243)  loss_rpn_box_reg: 0.1209 (0.2118)  time: 3.8708  data: 0.0969  max mem: 2501\n",
      "Epoch: [0]  [ 560/4489]  eta: 3:14:04  lr: 0.000118  loss: 0.1837 (0.3114)  loss_classifier: 0.0243 (0.0732)  loss_box_reg: 0.0002 (0.0030)  loss_objectness: 0.0011 (0.0238)  loss_rpn_box_reg: 0.1560 (0.2113)  time: 3.8643  data: 0.0963  max mem: 2501\n",
      "Epoch: [0]  [ 570/4489]  eta: 3:14:38  lr: 0.000120  loss: 0.2155 (0.3096)  loss_classifier: 0.0243 (0.0725)  loss_box_reg: 0.0002 (0.0030)  loss_objectness: 0.0014 (0.0235)  loss_rpn_box_reg: 0.1797 (0.2106)  time: 3.8692  data: 0.0950  max mem: 2501\n",
      "Epoch: [0]  [ 580/4489]  eta: 3:16:22  lr: 0.000122  loss: 0.1810 (0.3075)  loss_classifier: 0.0272 (0.0718)  loss_box_reg: 0.0002 (0.0029)  loss_objectness: 0.0025 (0.0231)  loss_rpn_box_reg: 0.1531 (0.2096)  time: 4.4275  data: 0.0963  max mem: 2501\n",
      "Epoch: [0]  [ 590/4489]  eta: 3:16:48  lr: 0.000124  loss: 0.1967 (0.3058)  loss_classifier: 0.0240 (0.0710)  loss_box_reg: 0.0001 (0.0029)  loss_objectness: 0.0009 (0.0228)  loss_rpn_box_reg: 0.1597 (0.2092)  time: 4.4216  data: 0.0949  max mem: 2501\n",
      "Epoch: [0]  [ 600/4489]  eta: 3:17:13  lr: 0.000126  loss: 0.1977 (0.3042)  loss_classifier: 0.0272 (0.0703)  loss_box_reg: 0.0001 (0.0029)  loss_objectness: 0.0009 (0.0224)  loss_rpn_box_reg: 0.1757 (0.2087)  time: 3.8754  data: 0.0949  max mem: 2501\n",
      "Epoch: [0]  [ 610/4489]  eta: 3:17:36  lr: 0.000128  loss: 0.1974 (0.3023)  loss_classifier: 0.0265 (0.0695)  loss_box_reg: 0.0009 (0.0028)  loss_objectness: 0.0014 (0.0221)  loss_rpn_box_reg: 0.1739 (0.2079)  time: 3.8809  data: 0.0987  max mem: 2501\n",
      "Epoch: [0]  [ 620/4489]  eta: 3:17:57  lr: 0.000130  loss: 0.1706 (0.3008)  loss_classifier: 0.0272 (0.0690)  loss_box_reg: 0.0009 (0.0028)  loss_objectness: 0.0023 (0.0218)  loss_rpn_box_reg: 0.1320 (0.2072)  time: 3.8849  data: 0.0993  max mem: 2501\n",
      "Epoch: [0]  [ 630/4489]  eta: 3:18:15  lr: 0.000132  loss: 0.1726 (0.2993)  loss_classifier: 0.0286 (0.0683)  loss_box_reg: 0.0009 (0.0028)  loss_objectness: 0.0026 (0.0215)  loss_rpn_box_reg: 0.1435 (0.2067)  time: 3.8782  data: 0.0976  max mem: 2501\n",
      "Epoch: [0]  [ 640/4489]  eta: 3:18:32  lr: 0.000135  loss: 0.1708 (0.2974)  loss_classifier: 0.0252 (0.0677)  loss_box_reg: 0.0009 (0.0027)  loss_objectness: 0.0013 (0.0212)  loss_rpn_box_reg: 0.1424 (0.2058)  time: 3.8687  data: 0.0981  max mem: 2501\n",
      "Epoch: [0]  [ 650/4489]  eta: 3:18:48  lr: 0.000137  loss: 0.1541 (0.2963)  loss_classifier: 0.0278 (0.0672)  loss_box_reg: 0.0004 (0.0027)  loss_objectness: 0.0009 (0.0210)  loss_rpn_box_reg: 0.1176 (0.2055)  time: 3.8807  data: 0.0971  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 660/4489]  eta: 3:19:01  lr: 0.000139  loss: 0.1950 (0.2954)  loss_classifier: 0.0278 (0.0666)  loss_box_reg: 0.0001 (0.0027)  loss_objectness: 0.0009 (0.0207)  loss_rpn_box_reg: 0.1749 (0.2054)  time: 3.8845  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [ 670/4489]  eta: 3:19:13  lr: 0.000141  loss: 0.1856 (0.2935)  loss_classifier: 0.0219 (0.0659)  loss_box_reg: 0.0001 (0.0026)  loss_objectness: 0.0010 (0.0205)  loss_rpn_box_reg: 0.1455 (0.2044)  time: 3.8707  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [ 680/4489]  eta: 3:19:23  lr: 0.000143  loss: 0.1435 (0.2914)  loss_classifier: 0.0197 (0.0653)  loss_box_reg: 0.0001 (0.0026)  loss_objectness: 0.0010 (0.0202)  loss_rpn_box_reg: 0.1192 (0.2033)  time: 3.8694  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [ 690/4489]  eta: 3:19:32  lr: 0.000145  loss: 0.1490 (0.2897)  loss_classifier: 0.0222 (0.0647)  loss_box_reg: 0.0001 (0.0026)  loss_objectness: 0.0009 (0.0199)  loss_rpn_box_reg: 0.1301 (0.2025)  time: 3.8753  data: 0.0988  max mem: 2501\n",
      "Epoch: [0]  [ 700/4489]  eta: 3:19:40  lr: 0.000147  loss: 0.1719 (0.2884)  loss_classifier: 0.0224 (0.0641)  loss_box_reg: 0.0001 (0.0025)  loss_objectness: 0.0008 (0.0197)  loss_rpn_box_reg: 0.1504 (0.2021)  time: 3.8761  data: 0.0991  max mem: 2501\n",
      "Epoch: [0]  [ 710/4489]  eta: 3:19:46  lr: 0.000149  loss: 0.1871 (0.2876)  loss_classifier: 0.0240 (0.0636)  loss_box_reg: 0.0001 (0.0025)  loss_objectness: 0.0013 (0.0194)  loss_rpn_box_reg: 0.1593 (0.2021)  time: 3.8751  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [ 720/4489]  eta: 3:19:52  lr: 0.000151  loss: 0.1871 (0.2857)  loss_classifier: 0.0256 (0.0631)  loss_box_reg: 0.0007 (0.0025)  loss_objectness: 0.0012 (0.0192)  loss_rpn_box_reg: 0.1579 (0.2010)  time: 3.8837  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [ 730/4489]  eta: 3:19:56  lr: 0.000153  loss: 0.1563 (0.2840)  loss_classifier: 0.0273 (0.0626)  loss_box_reg: 0.0006 (0.0025)  loss_objectness: 0.0009 (0.0189)  loss_rpn_box_reg: 0.1248 (0.2000)  time: 3.8846  data: 0.0985  max mem: 2501\n",
      "Epoch: [0]  [ 740/4489]  eta: 3:19:59  lr: 0.000156  loss: 0.1563 (0.2825)  loss_classifier: 0.0238 (0.0621)  loss_box_reg: 0.0006 (0.0024)  loss_objectness: 0.0010 (0.0187)  loss_rpn_box_reg: 0.1248 (0.1993)  time: 3.8790  data: 0.0985  max mem: 2501\n",
      "Epoch: [0]  [ 750/4489]  eta: 3:20:00  lr: 0.000158  loss: 0.1693 (0.2812)  loss_classifier: 0.0210 (0.0615)  loss_box_reg: 0.0002 (0.0024)  loss_objectness: 0.0009 (0.0185)  loss_rpn_box_reg: 0.1457 (0.1988)  time: 3.8752  data: 0.0987  max mem: 2501\n",
      "Epoch: [0]  [ 760/4489]  eta: 3:20:01  lr: 0.000160  loss: 0.1765 (0.2798)  loss_classifier: 0.0215 (0.0611)  loss_box_reg: 0.0002 (0.0024)  loss_objectness: 0.0012 (0.0183)  loss_rpn_box_reg: 0.1514 (0.1981)  time: 3.8760  data: 0.0978  max mem: 2501\n",
      "Epoch: [0]  [ 770/4489]  eta: 3:20:00  lr: 0.000162  loss: 0.1427 (0.2780)  loss_classifier: 0.0245 (0.0606)  loss_box_reg: 0.0006 (0.0024)  loss_objectness: 0.0012 (0.0180)  loss_rpn_box_reg: 0.1131 (0.1969)  time: 3.8778  data: 0.0982  max mem: 2501\n",
      "Epoch: [0]  [ 780/4489]  eta: 3:20:00  lr: 0.000164  loss: 0.1250 (0.2763)  loss_classifier: 0.0245 (0.0602)  loss_box_reg: 0.0007 (0.0024)  loss_objectness: 0.0014 (0.0179)  loss_rpn_box_reg: 0.0958 (0.1959)  time: 3.8821  data: 0.1011  max mem: 2501\n",
      "Epoch: [0]  [ 790/4489]  eta: 3:19:57  lr: 0.000166  loss: 0.1530 (0.2752)  loss_classifier: 0.0286 (0.0598)  loss_box_reg: 0.0007 (0.0024)  loss_objectness: 0.0013 (0.0177)  loss_rpn_box_reg: 0.1305 (0.1954)  time: 3.8846  data: 0.1009  max mem: 2501\n",
      "Epoch: [0]  [ 800/4489]  eta: 3:19:54  lr: 0.000168  loss: 0.1604 (0.2739)  loss_classifier: 0.0268 (0.0594)  loss_box_reg: 0.0005 (0.0023)  loss_objectness: 0.0009 (0.0175)  loss_rpn_box_reg: 0.1305 (0.1947)  time: 3.8779  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [ 810/4489]  eta: 3:20:41  lr: 0.000170  loss: 0.1682 (0.2730)  loss_classifier: 0.0280 (0.0590)  loss_box_reg: 0.0005 (0.0023)  loss_objectness: 0.0008 (0.0173)  loss_rpn_box_reg: 0.1509 (0.1944)  time: 4.4386  data: 0.1019  max mem: 2501\n",
      "Epoch: [0]  [ 820/4489]  eta: 3:20:34  lr: 0.000172  loss: 0.1855 (0.2717)  loss_classifier: 0.0270 (0.0586)  loss_box_reg: 0.0005 (0.0023)  loss_objectness: 0.0009 (0.0171)  loss_rpn_box_reg: 0.1617 (0.1937)  time: 4.4312  data: 0.1015  max mem: 2501\n",
      "Epoch: [0]  [ 830/4489]  eta: 3:20:28  lr: 0.000174  loss: 0.1873 (0.2708)  loss_classifier: 0.0270 (0.0582)  loss_box_reg: 0.0005 (0.0023)  loss_objectness: 0.0009 (0.0169)  loss_rpn_box_reg: 0.1645 (0.1934)  time: 3.8729  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [ 840/4489]  eta: 3:20:21  lr: 0.000176  loss: 0.1723 (0.2695)  loss_classifier: 0.0288 (0.0579)  loss_box_reg: 0.0005 (0.0023)  loss_objectness: 0.0008 (0.0167)  loss_rpn_box_reg: 0.1442 (0.1926)  time: 3.8799  data: 0.0935  max mem: 2501\n",
      "Epoch: [0]  [ 850/4489]  eta: 3:20:13  lr: 0.000179  loss: 0.1412 (0.2679)  loss_classifier: 0.0263 (0.0576)  loss_box_reg: 0.0005 (0.0022)  loss_objectness: 0.0009 (0.0166)  loss_rpn_box_reg: 0.1116 (0.1916)  time: 3.8817  data: 0.0942  max mem: 2501\n",
      "Epoch: [0]  [ 860/4489]  eta: 3:20:05  lr: 0.000181  loss: 0.1354 (0.2667)  loss_classifier: 0.0280 (0.0572)  loss_box_reg: 0.0005 (0.0022)  loss_objectness: 0.0007 (0.0164)  loss_rpn_box_reg: 0.0968 (0.1909)  time: 3.8864  data: 0.0981  max mem: 2501\n",
      "Epoch: [0]  [ 870/4489]  eta: 3:19:55  lr: 0.000183  loss: 0.1614 (0.2655)  loss_classifier: 0.0234 (0.0568)  loss_box_reg: 0.0004 (0.0022)  loss_objectness: 0.0006 (0.0162)  loss_rpn_box_reg: 0.1372 (0.1903)  time: 3.8769  data: 0.0993  max mem: 2501\n",
      "Epoch: [0]  [ 880/4489]  eta: 3:19:45  lr: 0.000185  loss: 0.1744 (0.2648)  loss_classifier: 0.0216 (0.0564)  loss_box_reg: 0.0001 (0.0022)  loss_objectness: 0.0010 (0.0161)  loss_rpn_box_reg: 0.1496 (0.1901)  time: 3.8697  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [ 890/4489]  eta: 3:19:34  lr: 0.000187  loss: 0.1727 (0.2639)  loss_classifier: 0.0216 (0.0560)  loss_box_reg: 0.0001 (0.0022)  loss_objectness: 0.0008 (0.0159)  loss_rpn_box_reg: 0.1496 (0.1898)  time: 3.8702  data: 0.0938  max mem: 2501\n",
      "Epoch: [0]  [ 900/4489]  eta: 3:19:22  lr: 0.000189  loss: 0.1727 (0.2630)  loss_classifier: 0.0212 (0.0557)  loss_box_reg: 0.0001 (0.0021)  loss_objectness: 0.0008 (0.0158)  loss_rpn_box_reg: 0.1575 (0.1894)  time: 3.8730  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [ 910/4489]  eta: 3:19:10  lr: 0.000191  loss: 0.1370 (0.2615)  loss_classifier: 0.0203 (0.0553)  loss_box_reg: 0.0001 (0.0021)  loss_objectness: 0.0013 (0.0156)  loss_rpn_box_reg: 0.1109 (0.1884)  time: 3.8786  data: 0.0961  max mem: 2501\n",
      "Epoch: [0]  [ 920/4489]  eta: 3:18:58  lr: 0.000193  loss: 0.1314 (0.2604)  loss_classifier: 0.0236 (0.0550)  loss_box_reg: 0.0001 (0.0021)  loss_objectness: 0.0013 (0.0155)  loss_rpn_box_reg: 0.1081 (0.1877)  time: 3.8862  data: 0.0974  max mem: 2501\n",
      "Epoch: [0]  [ 930/4489]  eta: 3:18:45  lr: 0.000195  loss: 0.1686 (0.2593)  loss_classifier: 0.0280 (0.0547)  loss_box_reg: 0.0001 (0.0021)  loss_objectness: 0.0010 (0.0153)  loss_rpn_box_reg: 0.1338 (0.1871)  time: 3.8830  data: 0.0964  max mem: 2501\n",
      "Epoch: [0]  [ 940/4489]  eta: 3:18:32  lr: 0.000197  loss: 0.1686 (0.2583)  loss_classifier: 0.0270 (0.0545)  loss_box_reg: 0.0005 (0.0021)  loss_objectness: 0.0008 (0.0152)  loss_rpn_box_reg: 0.1380 (0.1866)  time: 3.8794  data: 0.0944  max mem: 2501\n",
      "Epoch: [0]  [ 950/4489]  eta: 3:18:18  lr: 0.000200  loss: 0.1693 (0.2574)  loss_classifier: 0.0280 (0.0542)  loss_box_reg: 0.0008 (0.0021)  loss_objectness: 0.0008 (0.0151)  loss_rpn_box_reg: 0.1419 (0.1861)  time: 3.8794  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [ 960/4489]  eta: 3:18:03  lr: 0.000202  loss: 0.1693 (0.2566)  loss_classifier: 0.0272 (0.0539)  loss_box_reg: 0.0004 (0.0021)  loss_objectness: 0.0006 (0.0149)  loss_rpn_box_reg: 0.1417 (0.1857)  time: 3.8771  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [ 970/4489]  eta: 3:17:48  lr: 0.000204  loss: 0.1500 (0.2557)  loss_classifier: 0.0237 (0.0536)  loss_box_reg: 0.0001 (0.0021)  loss_objectness: 0.0006 (0.0148)  loss_rpn_box_reg: 0.1223 (0.1852)  time: 3.8793  data: 0.0945  max mem: 2501\n",
      "Epoch: [0]  [ 980/4489]  eta: 3:17:32  lr: 0.000206  loss: 0.1511 (0.2550)  loss_classifier: 0.0247 (0.0534)  loss_box_reg: 0.0001 (0.0020)  loss_objectness: 0.0006 (0.0146)  loss_rpn_box_reg: 0.1240 (0.1850)  time: 3.8772  data: 0.0924  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 990/4489]  eta: 3:17:16  lr: 0.000208  loss: 0.1672 (0.2543)  loss_classifier: 0.0262 (0.0531)  loss_box_reg: 0.0004 (0.0020)  loss_objectness: 0.0007 (0.0145)  loss_rpn_box_reg: 0.1391 (0.1846)  time: 3.8771  data: 0.0939  max mem: 2501\n",
      "Epoch: [0]  [1000/4489]  eta: 3:17:00  lr: 0.000210  loss: 0.1463 (0.2532)  loss_classifier: 0.0230 (0.0528)  loss_box_reg: 0.0002 (0.0020)  loss_objectness: 0.0008 (0.0144)  loss_rpn_box_reg: 0.1158 (0.1840)  time: 3.8808  data: 0.0949  max mem: 2501\n",
      "Epoch: [0]  [1010/4489]  eta: 3:16:43  lr: 0.000210  loss: 0.1541 (0.2525)  loss_classifier: 0.0246 (0.0526)  loss_box_reg: 0.0001 (0.0020)  loss_objectness: 0.0008 (0.0142)  loss_rpn_box_reg: 0.1100 (0.1836)  time: 3.8791  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [1020/4489]  eta: 3:16:25  lr: 0.000210  loss: 0.1564 (0.2514)  loss_classifier: 0.0288 (0.0524)  loss_box_reg: 0.0003 (0.0020)  loss_objectness: 0.0005 (0.0141)  loss_rpn_box_reg: 0.1143 (0.1830)  time: 3.8783  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [1030/4489]  eta: 3:16:07  lr: 0.000210  loss: 0.1491 (0.2506)  loss_classifier: 0.0282 (0.0521)  loss_box_reg: 0.0003 (0.0020)  loss_objectness: 0.0005 (0.0140)  loss_rpn_box_reg: 0.1077 (0.1825)  time: 3.8779  data: 0.0935  max mem: 2501\n",
      "Epoch: [0]  [1040/4489]  eta: 3:15:49  lr: 0.000210  loss: 0.1428 (0.2498)  loss_classifier: 0.0282 (0.0519)  loss_box_reg: 0.0003 (0.0020)  loss_objectness: 0.0006 (0.0139)  loss_rpn_box_reg: 0.1135 (0.1820)  time: 3.8787  data: 0.0945  max mem: 2501\n",
      "Epoch: [0]  [1050/4489]  eta: 3:16:06  lr: 0.000210  loss: 0.1689 (0.2490)  loss_classifier: 0.0239 (0.0517)  loss_box_reg: 0.0001 (0.0020)  loss_objectness: 0.0007 (0.0138)  loss_rpn_box_reg: 0.1355 (0.1816)  time: 4.4289  data: 0.0961  max mem: 2501\n",
      "Epoch: [0]  [1060/4489]  eta: 3:15:47  lr: 0.000210  loss: 0.1740 (0.2484)  loss_classifier: 0.0243 (0.0515)  loss_box_reg: 0.0001 (0.0019)  loss_objectness: 0.0006 (0.0137)  loss_rpn_box_reg: 0.1522 (0.1814)  time: 4.4313  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [1070/4489]  eta: 3:15:27  lr: 0.000210  loss: 0.1532 (0.2475)  loss_classifier: 0.0243 (0.0512)  loss_box_reg: 0.0002 (0.0019)  loss_objectness: 0.0005 (0.0135)  loss_rpn_box_reg: 0.1329 (0.1809)  time: 3.8816  data: 0.0938  max mem: 2501\n",
      "Epoch: [0]  [1080/4489]  eta: 3:15:07  lr: 0.000210  loss: 0.1592 (0.2468)  loss_classifier: 0.0224 (0.0510)  loss_box_reg: 0.0002 (0.0019)  loss_objectness: 0.0005 (0.0134)  loss_rpn_box_reg: 0.1223 (0.1805)  time: 3.8782  data: 0.0928  max mem: 2501\n",
      "Epoch: [0]  [1090/4489]  eta: 3:14:47  lr: 0.000210  loss: 0.1623 (0.2462)  loss_classifier: 0.0224 (0.0507)  loss_box_reg: 0.0003 (0.0019)  loss_objectness: 0.0007 (0.0133)  loss_rpn_box_reg: 0.1358 (0.1802)  time: 3.8810  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [1100/4489]  eta: 3:14:26  lr: 0.000210  loss: 0.1623 (0.2455)  loss_classifier: 0.0255 (0.0505)  loss_box_reg: 0.0003 (0.0019)  loss_objectness: 0.0006 (0.0132)  loss_rpn_box_reg: 0.1357 (0.1798)  time: 3.8817  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [1110/4489]  eta: 3:14:05  lr: 0.000210  loss: 0.1472 (0.2446)  loss_classifier: 0.0230 (0.0503)  loss_box_reg: 0.0002 (0.0019)  loss_objectness: 0.0004 (0.0131)  loss_rpn_box_reg: 0.1215 (0.1793)  time: 3.8785  data: 0.0942  max mem: 2501\n",
      "Epoch: [0]  [1120/4489]  eta: 3:13:43  lr: 0.000210  loss: 0.1476 (0.2437)  loss_classifier: 0.0230 (0.0501)  loss_box_reg: 0.0002 (0.0019)  loss_objectness: 0.0005 (0.0130)  loss_rpn_box_reg: 0.1115 (0.1787)  time: 3.8749  data: 0.0958  max mem: 2501\n",
      "Epoch: [0]  [1130/4489]  eta: 3:13:21  lr: 0.000210  loss: 0.1634 (0.2431)  loss_classifier: 0.0254 (0.0499)  loss_box_reg: 0.0001 (0.0019)  loss_objectness: 0.0005 (0.0129)  loss_rpn_box_reg: 0.1389 (0.1784)  time: 3.8765  data: 0.0972  max mem: 2501\n",
      "Epoch: [0]  [1140/4489]  eta: 3:12:59  lr: 0.000210  loss: 0.1634 (0.2423)  loss_classifier: 0.0254 (0.0497)  loss_box_reg: 0.0001 (0.0018)  loss_objectness: 0.0005 (0.0128)  loss_rpn_box_reg: 0.1389 (0.1780)  time: 3.8805  data: 0.0969  max mem: 2501\n",
      "Epoch: [0]  [1150/4489]  eta: 3:12:37  lr: 0.000210  loss: 0.1425 (0.2417)  loss_classifier: 0.0234 (0.0494)  loss_box_reg: 0.0001 (0.0018)  loss_objectness: 0.0005 (0.0127)  loss_rpn_box_reg: 0.1039 (0.1777)  time: 3.8788  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [1160/4489]  eta: 3:12:14  lr: 0.000210  loss: 0.1453 (0.2409)  loss_classifier: 0.0234 (0.0492)  loss_box_reg: 0.0002 (0.0018)  loss_objectness: 0.0006 (0.0126)  loss_rpn_box_reg: 0.1268 (0.1773)  time: 3.8739  data: 0.0931  max mem: 2501\n",
      "Epoch: [0]  [1170/4489]  eta: 3:11:51  lr: 0.000210  loss: 0.1453 (0.2402)  loss_classifier: 0.0249 (0.0490)  loss_box_reg: 0.0002 (0.0018)  loss_objectness: 0.0005 (0.0125)  loss_rpn_box_reg: 0.1159 (0.1769)  time: 3.8787  data: 0.0944  max mem: 2501\n",
      "Epoch: [0]  [1180/4489]  eta: 3:11:28  lr: 0.000210  loss: 0.1686 (0.2397)  loss_classifier: 0.0244 (0.0488)  loss_box_reg: 0.0001 (0.0018)  loss_objectness: 0.0005 (0.0124)  loss_rpn_box_reg: 0.1459 (0.1767)  time: 3.8818  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [1190/4489]  eta: 3:11:05  lr: 0.000210  loss: 0.1645 (0.2390)  loss_classifier: 0.0231 (0.0486)  loss_box_reg: 0.0001 (0.0018)  loss_objectness: 0.0005 (0.0123)  loss_rpn_box_reg: 0.1353 (0.1762)  time: 3.8796  data: 0.0975  max mem: 2501\n",
      "Epoch: [0]  [1200/4489]  eta: 3:10:41  lr: 0.000210  loss: 0.1413 (0.2383)  loss_classifier: 0.0250 (0.0484)  loss_box_reg: 0.0001 (0.0018)  loss_objectness: 0.0006 (0.0122)  loss_rpn_box_reg: 0.1253 (0.1759)  time: 3.8830  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [1210/4489]  eta: 3:10:17  lr: 0.000210  loss: 0.1535 (0.2377)  loss_classifier: 0.0267 (0.0483)  loss_box_reg: 0.0001 (0.0018)  loss_objectness: 0.0006 (0.0121)  loss_rpn_box_reg: 0.1236 (0.1755)  time: 3.8850  data: 0.0966  max mem: 2501\n",
      "Epoch: [0]  [1220/4489]  eta: 3:09:53  lr: 0.000210  loss: 0.1532 (0.2371)  loss_classifier: 0.0241 (0.0480)  loss_box_reg: 0.0002 (0.0018)  loss_objectness: 0.0006 (0.0120)  loss_rpn_box_reg: 0.1146 (0.1753)  time: 3.8815  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [1230/4489]  eta: 3:09:29  lr: 0.000210  loss: 0.1473 (0.2364)  loss_classifier: 0.0209 (0.0479)  loss_box_reg: 0.0002 (0.0017)  loss_objectness: 0.0005 (0.0120)  loss_rpn_box_reg: 0.1191 (0.1749)  time: 3.8791  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [1240/4489]  eta: 3:09:04  lr: 0.000210  loss: 0.1455 (0.2356)  loss_classifier: 0.0219 (0.0477)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0004 (0.0119)  loss_rpn_box_reg: 0.1191 (0.1744)  time: 3.8807  data: 0.0961  max mem: 2501\n",
      "Epoch: [0]  [1250/4489]  eta: 3:08:39  lr: 0.000210  loss: 0.1345 (0.2349)  loss_classifier: 0.0213 (0.0475)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0004 (0.0118)  loss_rpn_box_reg: 0.1138 (0.1740)  time: 3.8732  data: 0.0950  max mem: 2501\n",
      "Epoch: [0]  [1260/4489]  eta: 3:08:14  lr: 0.000210  loss: 0.1471 (0.2344)  loss_classifier: 0.0213 (0.0473)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0005 (0.0117)  loss_rpn_box_reg: 0.1187 (0.1737)  time: 3.8685  data: 0.0937  max mem: 2501\n",
      "Epoch: [0]  [1270/4489]  eta: 3:07:49  lr: 0.000210  loss: 0.1471 (0.2339)  loss_classifier: 0.0249 (0.0471)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0006 (0.0116)  loss_rpn_box_reg: 0.1251 (0.1734)  time: 3.8780  data: 0.0971  max mem: 2501\n",
      "Epoch: [0]  [1280/4489]  eta: 3:07:51  lr: 0.000210  loss: 0.1443 (0.2332)  loss_classifier: 0.0251 (0.0470)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0007 (0.0116)  loss_rpn_box_reg: 0.1210 (0.1730)  time: 4.4305  data: 0.0979  max mem: 2501\n",
      "Epoch: [0]  [1290/4489]  eta: 3:07:24  lr: 0.000210  loss: 0.1630 (0.2328)  loss_classifier: 0.0235 (0.0468)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0007 (0.0115)  loss_rpn_box_reg: 0.1342 (0.1729)  time: 4.4274  data: 0.0982  max mem: 2501\n",
      "Epoch: [0]  [1300/4489]  eta: 3:06:58  lr: 0.000210  loss: 0.1756 (0.2323)  loss_classifier: 0.0194 (0.0466)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0006 (0.0114)  loss_rpn_box_reg: 0.1479 (0.1726)  time: 3.8748  data: 0.0971  max mem: 2501\n",
      "Epoch: [0]  [1310/4489]  eta: 3:06:32  lr: 0.000210  loss: 0.1606 (0.2318)  loss_classifier: 0.0238 (0.0464)  loss_box_reg: 0.0001 (0.0017)  loss_objectness: 0.0005 (0.0113)  loss_rpn_box_reg: 0.1364 (0.1724)  time: 3.8776  data: 0.0952  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [1320/4489]  eta: 3:06:05  lr: 0.000210  loss: 0.1366 (0.2311)  loss_classifier: 0.0258 (0.0463)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0004 (0.0112)  loss_rpn_box_reg: 0.1080 (0.1719)  time: 3.8796  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [1330/4489]  eta: 3:05:38  lr: 0.000210  loss: 0.1366 (0.2305)  loss_classifier: 0.0255 (0.0461)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0004 (0.0112)  loss_rpn_box_reg: 0.1124 (0.1715)  time: 3.8791  data: 0.0978  max mem: 2501\n",
      "Epoch: [0]  [1340/4489]  eta: 3:05:11  lr: 0.000210  loss: 0.1525 (0.2299)  loss_classifier: 0.0230 (0.0459)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0006 (0.0111)  loss_rpn_box_reg: 0.1266 (0.1713)  time: 3.8760  data: 0.0982  max mem: 2501\n",
      "Epoch: [0]  [1350/4489]  eta: 3:04:44  lr: 0.000210  loss: 0.1500 (0.2294)  loss_classifier: 0.0230 (0.0458)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0006 (0.0110)  loss_rpn_box_reg: 0.1296 (0.1710)  time: 3.8754  data: 0.0967  max mem: 2501\n",
      "Epoch: [0]  [1360/4489]  eta: 3:04:17  lr: 0.000210  loss: 0.1288 (0.2286)  loss_classifier: 0.0237 (0.0456)  loss_box_reg: 0.0002 (0.0016)  loss_objectness: 0.0006 (0.0109)  loss_rpn_box_reg: 0.1092 (0.1705)  time: 3.8834  data: 0.0942  max mem: 2501\n",
      "Epoch: [0]  [1370/4489]  eta: 3:03:49  lr: 0.000210  loss: 0.1234 (0.2280)  loss_classifier: 0.0224 (0.0455)  loss_box_reg: 0.0002 (0.0016)  loss_objectness: 0.0005 (0.0109)  loss_rpn_box_reg: 0.0974 (0.1700)  time: 3.8841  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [1380/4489]  eta: 3:03:22  lr: 0.000210  loss: 0.1390 (0.2273)  loss_classifier: 0.0224 (0.0453)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0005 (0.0108)  loss_rpn_box_reg: 0.1067 (0.1695)  time: 3.8820  data: 0.0978  max mem: 2501\n",
      "Epoch: [0]  [1390/4489]  eta: 3:02:54  lr: 0.000210  loss: 0.1524 (0.2268)  loss_classifier: 0.0235 (0.0452)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0006 (0.0107)  loss_rpn_box_reg: 0.1258 (0.1693)  time: 3.8774  data: 0.0963  max mem: 2501\n",
      "Epoch: [0]  [1400/4489]  eta: 3:02:26  lr: 0.000210  loss: 0.1643 (0.2264)  loss_classifier: 0.0224 (0.0450)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0007 (0.0107)  loss_rpn_box_reg: 0.1338 (0.1691)  time: 3.8700  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [1410/4489]  eta: 3:01:58  lr: 0.000210  loss: 0.1307 (0.2258)  loss_classifier: 0.0211 (0.0449)  loss_box_reg: 0.0001 (0.0016)  loss_objectness: 0.0006 (0.0106)  loss_rpn_box_reg: 0.1088 (0.1687)  time: 3.8754  data: 0.0965  max mem: 2501\n",
      "Epoch: [0]  [1420/4489]  eta: 3:01:30  lr: 0.000210  loss: 0.1476 (0.2254)  loss_classifier: 0.0276 (0.0448)  loss_box_reg: 0.0002 (0.0016)  loss_objectness: 0.0006 (0.0105)  loss_rpn_box_reg: 0.1088 (0.1685)  time: 3.8873  data: 0.0971  max mem: 2501\n",
      "Epoch: [0]  [1430/4489]  eta: 3:01:01  lr: 0.000210  loss: 0.1481 (0.2250)  loss_classifier: 0.0249 (0.0446)  loss_box_reg: 0.0003 (0.0016)  loss_objectness: 0.0006 (0.0105)  loss_rpn_box_reg: 0.1204 (0.1683)  time: 3.8849  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [1440/4489]  eta: 3:00:33  lr: 0.000210  loss: 0.1372 (0.2244)  loss_classifier: 0.0217 (0.0445)  loss_box_reg: 0.0002 (0.0016)  loss_objectness: 0.0005 (0.0104)  loss_rpn_box_reg: 0.1188 (0.1679)  time: 3.8786  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [1450/4489]  eta: 3:00:04  lr: 0.000210  loss: 0.1405 (0.2239)  loss_classifier: 0.0239 (0.0444)  loss_box_reg: 0.0002 (0.0015)  loss_objectness: 0.0004 (0.0104)  loss_rpn_box_reg: 0.1137 (0.1676)  time: 3.8750  data: 0.0946  max mem: 2501\n",
      "Epoch: [0]  [1460/4489]  eta: 2:59:35  lr: 0.000210  loss: 0.1494 (0.2235)  loss_classifier: 0.0253 (0.0442)  loss_box_reg: 0.0002 (0.0015)  loss_objectness: 0.0006 (0.0103)  loss_rpn_box_reg: 0.1223 (0.1674)  time: 3.8692  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [1470/4489]  eta: 2:59:06  lr: 0.000210  loss: 0.1619 (0.2231)  loss_classifier: 0.0221 (0.0441)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0006 (0.0102)  loss_rpn_box_reg: 0.1223 (0.1672)  time: 3.8763  data: 0.0950  max mem: 2501\n",
      "Epoch: [0]  [1480/4489]  eta: 2:58:37  lr: 0.000210  loss: 0.1622 (0.2227)  loss_classifier: 0.0241 (0.0440)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0006 (0.0102)  loss_rpn_box_reg: 0.1351 (0.1670)  time: 3.8800  data: 0.0955  max mem: 2501\n",
      "Epoch: [0]  [1490/4489]  eta: 2:58:07  lr: 0.000210  loss: 0.1621 (0.2223)  loss_classifier: 0.0241 (0.0439)  loss_box_reg: 0.0002 (0.0015)  loss_objectness: 0.0006 (0.0101)  loss_rpn_box_reg: 0.1360 (0.1668)  time: 3.8765  data: 0.0954  max mem: 2501\n",
      "Epoch: [0]  [1500/4489]  eta: 2:57:38  lr: 0.000210  loss: 0.1334 (0.2218)  loss_classifier: 0.0227 (0.0437)  loss_box_reg: 0.0002 (0.0015)  loss_objectness: 0.0005 (0.0101)  loss_rpn_box_reg: 0.1130 (0.1665)  time: 3.8794  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [1510/4489]  eta: 2:57:30  lr: 0.000210  loss: 0.1312 (0.2214)  loss_classifier: 0.0207 (0.0436)  loss_box_reg: 0.0002 (0.0015)  loss_objectness: 0.0005 (0.0100)  loss_rpn_box_reg: 0.1024 (0.1663)  time: 4.4230  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [1520/4489]  eta: 2:57:00  lr: 0.000210  loss: 0.1568 (0.2210)  loss_classifier: 0.0206 (0.0435)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0005 (0.0099)  loss_rpn_box_reg: 0.1353 (0.1661)  time: 4.4241  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [1530/4489]  eta: 2:56:30  lr: 0.000210  loss: 0.1423 (0.2204)  loss_classifier: 0.0206 (0.0434)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0004 (0.0099)  loss_rpn_box_reg: 0.1198 (0.1657)  time: 3.8792  data: 0.0977  max mem: 2501\n",
      "Epoch: [0]  [1540/4489]  eta: 2:56:00  lr: 0.000210  loss: 0.1350 (0.2200)  loss_classifier: 0.0168 (0.0432)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0005 (0.0098)  loss_rpn_box_reg: 0.1103 (0.1655)  time: 3.8689  data: 0.0982  max mem: 2501\n",
      "Epoch: [0]  [1550/4489]  eta: 2:55:30  lr: 0.000210  loss: 0.1498 (0.2197)  loss_classifier: 0.0209 (0.0431)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0006 (0.0098)  loss_rpn_box_reg: 0.1196 (0.1653)  time: 3.8737  data: 0.0958  max mem: 2501\n",
      "Epoch: [0]  [1560/4489]  eta: 2:55:00  lr: 0.000210  loss: 0.1605 (0.2193)  loss_classifier: 0.0257 (0.0430)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0004 (0.0097)  loss_rpn_box_reg: 0.1204 (0.1651)  time: 3.8816  data: 0.0955  max mem: 2501\n",
      "Epoch: [0]  [1570/4489]  eta: 2:54:29  lr: 0.000210  loss: 0.1471 (0.2188)  loss_classifier: 0.0231 (0.0429)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0004 (0.0097)  loss_rpn_box_reg: 0.1281 (0.1648)  time: 3.8758  data: 0.0969  max mem: 2501\n",
      "Epoch: [0]  [1580/4489]  eta: 2:53:59  lr: 0.000210  loss: 0.1458 (0.2183)  loss_classifier: 0.0220 (0.0428)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0006 (0.0096)  loss_rpn_box_reg: 0.0937 (0.1645)  time: 3.8770  data: 0.0975  max mem: 2501\n",
      "Epoch: [0]  [1590/4489]  eta: 2:53:28  lr: 0.000210  loss: 0.1333 (0.2178)  loss_classifier: 0.0220 (0.0427)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0004 (0.0096)  loss_rpn_box_reg: 0.0968 (0.1642)  time: 3.8802  data: 0.0979  max mem: 2501\n",
      "Epoch: [0]  [1600/4489]  eta: 2:52:58  lr: 0.000210  loss: 0.1444 (0.2175)  loss_classifier: 0.0188 (0.0425)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0003 (0.0095)  loss_rpn_box_reg: 0.1169 (0.1640)  time: 3.8851  data: 0.1025  max mem: 2501\n",
      "Epoch: [0]  [1610/4489]  eta: 2:52:27  lr: 0.000210  loss: 0.1444 (0.2171)  loss_classifier: 0.0211 (0.0424)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0004 (0.0095)  loss_rpn_box_reg: 0.1012 (0.1638)  time: 3.8839  data: 0.1002  max mem: 2501\n",
      "Epoch: [0]  [1620/4489]  eta: 2:51:56  lr: 0.000210  loss: 0.1372 (0.2167)  loss_classifier: 0.0231 (0.0423)  loss_box_reg: 0.0001 (0.0015)  loss_objectness: 0.0004 (0.0094)  loss_rpn_box_reg: 0.1012 (0.1636)  time: 3.8736  data: 0.0944  max mem: 2501\n",
      "Epoch: [0]  [1630/4489]  eta: 2:51:25  lr: 0.000210  loss: 0.1467 (0.2163)  loss_classifier: 0.0213 (0.0422)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0093)  loss_rpn_box_reg: 0.1291 (0.1634)  time: 3.8711  data: 0.0935  max mem: 2501\n",
      "Epoch: [0]  [1640/4489]  eta: 2:50:53  lr: 0.000210  loss: 0.1423 (0.2158)  loss_classifier: 0.0242 (0.0421)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0093)  loss_rpn_box_reg: 0.1088 (0.1630)  time: 3.8763  data: 0.0939  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [1650/4489]  eta: 2:50:22  lr: 0.000210  loss: 0.1423 (0.2155)  loss_classifier: 0.0235 (0.0420)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0092)  loss_rpn_box_reg: 0.1136 (0.1628)  time: 3.8771  data: 0.0924  max mem: 2501\n",
      "Epoch: [0]  [1660/4489]  eta: 2:49:51  lr: 0.000210  loss: 0.1528 (0.2152)  loss_classifier: 0.0182 (0.0419)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0005 (0.0092)  loss_rpn_box_reg: 0.1219 (0.1628)  time: 3.8700  data: 0.0941  max mem: 2501\n",
      "Epoch: [0]  [1670/4489]  eta: 2:49:19  lr: 0.000210  loss: 0.1511 (0.2150)  loss_classifier: 0.0154 (0.0417)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0005 (0.0091)  loss_rpn_box_reg: 0.1381 (0.1627)  time: 3.8571  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [1680/4489]  eta: 2:48:47  lr: 0.000210  loss: 0.1847 (0.2148)  loss_classifier: 0.0191 (0.0416)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0005 (0.0091)  loss_rpn_box_reg: 0.1588 (0.1627)  time: 3.8542  data: 0.0965  max mem: 2501\n",
      "Epoch: [0]  [1690/4489]  eta: 2:48:15  lr: 0.000210  loss: 0.1651 (0.2145)  loss_classifier: 0.0205 (0.0415)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0091)  loss_rpn_box_reg: 0.1484 (0.1626)  time: 3.8657  data: 0.0973  max mem: 2501\n",
      "Epoch: [0]  [1700/4489]  eta: 2:47:44  lr: 0.000210  loss: 0.1572 (0.2142)  loss_classifier: 0.0196 (0.0414)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0090)  loss_rpn_box_reg: 0.1361 (0.1624)  time: 3.8689  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [1710/4489]  eta: 2:47:12  lr: 0.000210  loss: 0.1673 (0.2140)  loss_classifier: 0.0209 (0.0413)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0090)  loss_rpn_box_reg: 0.1366 (0.1623)  time: 3.8721  data: 0.0954  max mem: 2501\n",
      "Epoch: [0]  [1720/4489]  eta: 2:46:40  lr: 0.000210  loss: 0.1494 (0.2135)  loss_classifier: 0.0209 (0.0412)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0006 (0.0089)  loss_rpn_box_reg: 0.1271 (0.1620)  time: 3.8656  data: 0.0954  max mem: 2501\n",
      "Epoch: [0]  [1730/4489]  eta: 2:46:08  lr: 0.000210  loss: 0.1347 (0.2132)  loss_classifier: 0.0202 (0.0411)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0007 (0.0089)  loss_rpn_box_reg: 0.1132 (0.1618)  time: 3.8629  data: 0.0928  max mem: 2501\n",
      "Epoch: [0]  [1740/4489]  eta: 2:45:53  lr: 0.000210  loss: 0.1425 (0.2129)  loss_classifier: 0.0280 (0.0410)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0005 (0.0088)  loss_rpn_box_reg: 0.1175 (0.1616)  time: 4.4289  data: 0.0930  max mem: 2501\n",
      "Epoch: [0]  [1750/4489]  eta: 2:45:21  lr: 0.000210  loss: 0.1482 (0.2124)  loss_classifier: 0.0281 (0.0410)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0088)  loss_rpn_box_reg: 0.1146 (0.1613)  time: 4.4292  data: 0.0955  max mem: 2501\n",
      "Epoch: [0]  [1760/4489]  eta: 2:44:48  lr: 0.000210  loss: 0.1427 (0.2120)  loss_classifier: 0.0207 (0.0408)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0087)  loss_rpn_box_reg: 0.1196 (0.1611)  time: 3.8655  data: 0.0961  max mem: 2501\n",
      "Epoch: [0]  [1770/4489]  eta: 2:44:16  lr: 0.000210  loss: 0.1233 (0.2115)  loss_classifier: 0.0183 (0.0407)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0087)  loss_rpn_box_reg: 0.0992 (0.1607)  time: 3.8698  data: 0.0966  max mem: 2501\n",
      "Epoch: [0]  [1780/4489]  eta: 2:43:44  lr: 0.000210  loss: 0.1233 (0.2111)  loss_classifier: 0.0213 (0.0407)  loss_box_reg: 0.0001 (0.0014)  loss_objectness: 0.0004 (0.0086)  loss_rpn_box_reg: 0.0992 (0.1605)  time: 3.8788  data: 0.0963  max mem: 2501\n",
      "Epoch: [0]  [1790/4489]  eta: 2:43:11  lr: 0.000210  loss: 0.1323 (0.2106)  loss_classifier: 0.0254 (0.0406)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0086)  loss_rpn_box_reg: 0.0885 (0.1601)  time: 3.8735  data: 0.0941  max mem: 2501\n",
      "Epoch: [0]  [1800/4489]  eta: 2:42:39  lr: 0.000210  loss: 0.1192 (0.2102)  loss_classifier: 0.0242 (0.0405)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0086)  loss_rpn_box_reg: 0.0932 (0.1598)  time: 3.8744  data: 0.0964  max mem: 2501\n",
      "Epoch: [0]  [1810/4489]  eta: 2:42:06  lr: 0.000210  loss: 0.1426 (0.2099)  loss_classifier: 0.0218 (0.0404)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0085)  loss_rpn_box_reg: 0.1131 (0.1596)  time: 3.8772  data: 0.0967  max mem: 2501\n",
      "Epoch: [0]  [1820/4489]  eta: 2:41:33  lr: 0.000210  loss: 0.1333 (0.2095)  loss_classifier: 0.0236 (0.0403)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0085)  loss_rpn_box_reg: 0.1116 (0.1594)  time: 3.8707  data: 0.0934  max mem: 2501\n",
      "Epoch: [0]  [1830/4489]  eta: 2:41:00  lr: 0.000210  loss: 0.1256 (0.2092)  loss_classifier: 0.0236 (0.0402)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0084)  loss_rpn_box_reg: 0.1050 (0.1592)  time: 3.8706  data: 0.0922  max mem: 2501\n",
      "Epoch: [0]  [1840/4489]  eta: 2:40:27  lr: 0.000210  loss: 0.1363 (0.2089)  loss_classifier: 0.0223 (0.0402)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0084)  loss_rpn_box_reg: 0.1125 (0.1591)  time: 3.8705  data: 0.0925  max mem: 2501\n",
      "Epoch: [0]  [1850/4489]  eta: 2:39:54  lr: 0.000210  loss: 0.1383 (0.2086)  loss_classifier: 0.0192 (0.0401)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0084)  loss_rpn_box_reg: 0.1182 (0.1589)  time: 3.8716  data: 0.0928  max mem: 2501\n",
      "Epoch: [0]  [1860/4489]  eta: 2:39:21  lr: 0.000210  loss: 0.1383 (0.2083)  loss_classifier: 0.0215 (0.0400)  loss_box_reg: 0.0002 (0.0013)  loss_objectness: 0.0004 (0.0083)  loss_rpn_box_reg: 0.1081 (0.1587)  time: 3.8759  data: 0.0936  max mem: 2501\n",
      "Epoch: [0]  [1870/4489]  eta: 2:38:48  lr: 0.000210  loss: 0.1395 (0.2081)  loss_classifier: 0.0211 (0.0399)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0083)  loss_rpn_box_reg: 0.1134 (0.1586)  time: 3.8651  data: 0.0927  max mem: 2501\n",
      "Epoch: [0]  [1880/4489]  eta: 2:38:15  lr: 0.000210  loss: 0.1482 (0.2079)  loss_classifier: 0.0211 (0.0398)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0082)  loss_rpn_box_reg: 0.1334 (0.1585)  time: 3.8713  data: 0.0920  max mem: 2501\n",
      "Epoch: [0]  [1890/4489]  eta: 2:37:42  lr: 0.000210  loss: 0.1451 (0.2076)  loss_classifier: 0.0262 (0.0397)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0005 (0.0082)  loss_rpn_box_reg: 0.1267 (0.1583)  time: 3.8841  data: 0.0953  max mem: 2501\n",
      "Epoch: [0]  [1900/4489]  eta: 2:37:09  lr: 0.000210  loss: 0.1298 (0.2072)  loss_classifier: 0.0223 (0.0396)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0082)  loss_rpn_box_reg: 0.0989 (0.1581)  time: 3.8777  data: 0.0966  max mem: 2501\n",
      "Epoch: [0]  [1910/4489]  eta: 2:36:35  lr: 0.000210  loss: 0.1332 (0.2069)  loss_classifier: 0.0229 (0.0396)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0005 (0.0081)  loss_rpn_box_reg: 0.1032 (0.1579)  time: 3.8679  data: 0.0945  max mem: 2501\n",
      "Epoch: [0]  [1920/4489]  eta: 2:36:02  lr: 0.000210  loss: 0.1490 (0.2067)  loss_classifier: 0.0223 (0.0395)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0006 (0.0081)  loss_rpn_box_reg: 0.1288 (0.1579)  time: 3.8650  data: 0.0937  max mem: 2501\n",
      "Epoch: [0]  [1930/4489]  eta: 2:35:29  lr: 0.000210  loss: 0.1873 (0.2066)  loss_classifier: 0.0193 (0.0394)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0005 (0.0081)  loss_rpn_box_reg: 0.1635 (0.1579)  time: 3.8679  data: 0.0928  max mem: 2501\n",
      "Epoch: [0]  [1940/4489]  eta: 2:34:55  lr: 0.000210  loss: 0.1799 (0.2063)  loss_classifier: 0.0207 (0.0393)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0005 (0.0080)  loss_rpn_box_reg: 0.1585 (0.1577)  time: 3.8698  data: 0.0938  max mem: 2501\n",
      "Epoch: [0]  [1950/4489]  eta: 2:34:22  lr: 0.000210  loss: 0.1241 (0.2059)  loss_classifier: 0.0204 (0.0392)  loss_box_reg: 0.0001 (0.0013)  loss_objectness: 0.0004 (0.0080)  loss_rpn_box_reg: 0.0964 (0.1575)  time: 3.8698  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [1960/4489]  eta: 2:33:48  lr: 0.000210  loss: 0.1339 (0.2056)  loss_classifier: 0.0207 (0.0391)  loss_box_reg: 0.0002 (0.0013)  loss_objectness: 0.0005 (0.0080)  loss_rpn_box_reg: 0.1118 (0.1573)  time: 3.8705  data: 0.0953  max mem: 2501\n",
      "Epoch: [0]  [1970/4489]  eta: 2:33:28  lr: 0.000210  loss: 0.1487 (0.2054)  loss_classifier: 0.0208 (0.0390)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0007 (0.0079)  loss_rpn_box_reg: 0.1297 (0.1572)  time: 4.4211  data: 0.0952  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [1980/4489]  eta: 2:32:54  lr: 0.000210  loss: 0.1465 (0.2051)  loss_classifier: 0.0187 (0.0389)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0006 (0.0079)  loss_rpn_box_reg: 0.1182 (0.1570)  time: 4.4169  data: 0.0936  max mem: 2501\n",
      "Epoch: [0]  [1990/4489]  eta: 2:32:21  lr: 0.000210  loss: 0.1235 (0.2047)  loss_classifier: 0.0253 (0.0389)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0005 (0.0078)  loss_rpn_box_reg: 0.1037 (0.1567)  time: 3.8714  data: 0.0931  max mem: 2501\n",
      "Epoch: [0]  [2000/4489]  eta: 2:31:47  lr: 0.000210  loss: 0.1054 (0.2042)  loss_classifier: 0.0281 (0.0388)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0004 (0.0078)  loss_rpn_box_reg: 0.0805 (0.1563)  time: 3.8751  data: 0.0929  max mem: 2501\n",
      "Epoch: [0]  [2010/4489]  eta: 2:31:13  lr: 0.000210  loss: 0.1054 (0.2038)  loss_classifier: 0.0240 (0.0388)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0003 (0.0078)  loss_rpn_box_reg: 0.0805 (0.1560)  time: 3.8762  data: 0.0946  max mem: 2501\n",
      "Epoch: [0]  [2020/4489]  eta: 2:30:39  lr: 0.000210  loss: 0.1310 (0.2035)  loss_classifier: 0.0223 (0.0387)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0003 (0.0078)  loss_rpn_box_reg: 0.0948 (0.1558)  time: 3.8781  data: 0.0972  max mem: 2501\n",
      "Epoch: [0]  [2030/4489]  eta: 2:30:05  lr: 0.000210  loss: 0.1303 (0.2031)  loss_classifier: 0.0206 (0.0386)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0006 (0.0077)  loss_rpn_box_reg: 0.0981 (0.1555)  time: 3.8689  data: 0.0968  max mem: 2501\n",
      "Epoch: [0]  [2040/4489]  eta: 2:29:31  lr: 0.000210  loss: 0.1296 (0.2028)  loss_classifier: 0.0210 (0.0386)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0006 (0.0077)  loss_rpn_box_reg: 0.0913 (0.1553)  time: 3.8684  data: 0.0956  max mem: 2501\n",
      "Epoch: [0]  [2050/4489]  eta: 2:28:57  lr: 0.000210  loss: 0.1148 (0.2023)  loss_classifier: 0.0249 (0.0385)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0006 (0.0077)  loss_rpn_box_reg: 0.0867 (0.1550)  time: 3.8777  data: 0.0968  max mem: 2501\n",
      "Epoch: [0]  [2060/4489]  eta: 2:28:22  lr: 0.000210  loss: 0.1103 (0.2020)  loss_classifier: 0.0249 (0.0385)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0005 (0.0076)  loss_rpn_box_reg: 0.0818 (0.1547)  time: 3.8780  data: 0.0970  max mem: 2501\n",
      "Epoch: [0]  [2070/4489]  eta: 2:27:48  lr: 0.000210  loss: 0.1172 (0.2017)  loss_classifier: 0.0295 (0.0384)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0005 (0.0076)  loss_rpn_box_reg: 0.0818 (0.1544)  time: 3.8806  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [2080/4489]  eta: 2:27:14  lr: 0.000210  loss: 0.1159 (0.2013)  loss_classifier: 0.0290 (0.0384)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0005 (0.0076)  loss_rpn_box_reg: 0.0741 (0.1542)  time: 3.8795  data: 0.0937  max mem: 2501\n",
      "Epoch: [0]  [2090/4489]  eta: 2:26:40  lr: 0.000210  loss: 0.1111 (0.2010)  loss_classifier: 0.0263 (0.0383)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0006 (0.0075)  loss_rpn_box_reg: 0.0836 (0.1539)  time: 3.8670  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [2100/4489]  eta: 2:26:05  lr: 0.000210  loss: 0.1121 (0.2006)  loss_classifier: 0.0232 (0.0383)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0006 (0.0075)  loss_rpn_box_reg: 0.0843 (0.1536)  time: 3.8671  data: 0.0944  max mem: 2501\n",
      "Epoch: [0]  [2110/4489]  eta: 2:25:31  lr: 0.000210  loss: 0.1170 (0.2002)  loss_classifier: 0.0221 (0.0382)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0006 (0.0075)  loss_rpn_box_reg: 0.0921 (0.1533)  time: 3.8775  data: 0.0941  max mem: 2501\n",
      "Epoch: [0]  [2120/4489]  eta: 2:24:56  lr: 0.000210  loss: 0.1053 (0.1998)  loss_classifier: 0.0215 (0.0381)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0006 (0.0075)  loss_rpn_box_reg: 0.0813 (0.1530)  time: 3.8753  data: 0.0946  max mem: 2501\n",
      "Epoch: [0]  [2130/4489]  eta: 2:24:22  lr: 0.000210  loss: 0.0969 (0.1994)  loss_classifier: 0.0244 (0.0381)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0004 (0.0074)  loss_rpn_box_reg: 0.0760 (0.1527)  time: 3.8800  data: 0.0986  max mem: 2501\n",
      "Epoch: [0]  [2140/4489]  eta: 2:23:48  lr: 0.000210  loss: 0.1167 (0.1991)  loss_classifier: 0.0233 (0.0380)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0004 (0.0074)  loss_rpn_box_reg: 0.0900 (0.1525)  time: 3.8787  data: 0.0991  max mem: 2501\n",
      "Epoch: [0]  [2150/4489]  eta: 2:23:13  lr: 0.000210  loss: 0.1167 (0.1988)  loss_classifier: 0.0227 (0.0380)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0004 (0.0074)  loss_rpn_box_reg: 0.0977 (0.1523)  time: 3.8632  data: 0.0948  max mem: 2501\n",
      "Epoch: [0]  [2160/4489]  eta: 2:22:38  lr: 0.000210  loss: 0.1158 (0.1985)  loss_classifier: 0.0239 (0.0379)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0004 (0.0073)  loss_rpn_box_reg: 0.0920 (0.1521)  time: 3.8673  data: 0.0933  max mem: 2501\n",
      "Epoch: [0]  [2170/4489]  eta: 2:22:04  lr: 0.000210  loss: 0.1103 (0.1981)  loss_classifier: 0.0233 (0.0379)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0004 (0.0073)  loss_rpn_box_reg: 0.0840 (0.1517)  time: 3.8716  data: 0.0950  max mem: 2501\n",
      "Epoch: [0]  [2180/4489]  eta: 2:21:29  lr: 0.000210  loss: 0.1108 (0.1978)  loss_classifier: 0.0222 (0.0378)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0004 (0.0073)  loss_rpn_box_reg: 0.0854 (0.1515)  time: 3.8678  data: 0.0982  max mem: 2501\n",
      "Epoch: [0]  [2190/4489]  eta: 2:20:54  lr: 0.000210  loss: 0.1146 (0.1974)  loss_classifier: 0.0224 (0.0378)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0004 (0.0072)  loss_rpn_box_reg: 0.0863 (0.1512)  time: 3.8635  data: 0.0968  max mem: 2501\n",
      "Epoch: [0]  [2200/4489]  eta: 2:20:19  lr: 0.000210  loss: 0.1146 (0.1971)  loss_classifier: 0.0222 (0.0377)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0004 (0.0072)  loss_rpn_box_reg: 0.0940 (0.1510)  time: 3.8585  data: 0.0940  max mem: 2501\n",
      "Epoch: [0]  [2210/4489]  eta: 2:19:56  lr: 0.000210  loss: 0.1177 (0.1967)  loss_classifier: 0.0194 (0.0376)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0004 (0.0072)  loss_rpn_box_reg: 0.0965 (0.1508)  time: 4.4047  data: 0.0959  max mem: 2501\n",
      "Epoch: [0]  [2220/4489]  eta: 2:19:20  lr: 0.000210  loss: 0.1307 (0.1965)  loss_classifier: 0.0174 (0.0375)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0006 (0.0072)  loss_rpn_box_reg: 0.0982 (0.1506)  time: 4.4038  data: 0.0964  max mem: 2501\n",
      "Epoch: [0]  [2230/4489]  eta: 2:18:45  lr: 0.000210  loss: 0.1366 (0.1962)  loss_classifier: 0.0228 (0.0375)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0006 (0.0071)  loss_rpn_box_reg: 0.1083 (0.1504)  time: 3.8590  data: 0.0958  max mem: 2501\n",
      "Epoch: [0]  [2240/4489]  eta: 2:18:10  lr: 0.000210  loss: 0.1360 (0.1959)  loss_classifier: 0.0261 (0.0375)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0004 (0.0071)  loss_rpn_box_reg: 0.0979 (0.1502)  time: 3.8643  data: 0.0968  max mem: 2501\n",
      "Epoch: [0]  [2250/4489]  eta: 2:17:35  lr: 0.000210  loss: 0.1388 (0.1958)  loss_classifier: 0.0203 (0.0374)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0005 (0.0071)  loss_rpn_box_reg: 0.0979 (0.1501)  time: 3.8613  data: 0.0944  max mem: 2501\n",
      "Epoch: [0]  [2260/4489]  eta: 2:17:00  lr: 0.000210  loss: 0.1544 (0.1956)  loss_classifier: 0.0210 (0.0373)  loss_box_reg: 0.0001 (0.0012)  loss_objectness: 0.0005 (0.0071)  loss_rpn_box_reg: 0.1207 (0.1500)  time: 3.8652  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [2270/4489]  eta: 2:16:25  lr: 0.000210  loss: 0.1335 (0.1953)  loss_classifier: 0.0251 (0.0373)  loss_box_reg: 0.0002 (0.0012)  loss_objectness: 0.0005 (0.0070)  loss_rpn_box_reg: 0.1079 (0.1498)  time: 3.8677  data: 0.0974  max mem: 2501\n",
      "Epoch: [0]  [2280/4489]  eta: 2:15:50  lr: 0.000210  loss: 0.1280 (0.1950)  loss_classifier: 0.0262 (0.0372)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0007 (0.0070)  loss_rpn_box_reg: 0.0965 (0.1496)  time: 3.8649  data: 0.0954  max mem: 2501\n",
      "Epoch: [0]  [2290/4489]  eta: 2:15:15  lr: 0.000210  loss: 0.1224 (0.1946)  loss_classifier: 0.0247 (0.0372)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0007 (0.0070)  loss_rpn_box_reg: 0.0912 (0.1493)  time: 3.8655  data: 0.0946  max mem: 2501\n",
      "Epoch: [0]  [2300/4489]  eta: 2:14:39  lr: 0.000210  loss: 0.1224 (0.1944)  loss_classifier: 0.0230 (0.0372)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0070)  loss_rpn_box_reg: 0.0912 (0.1491)  time: 3.8613  data: 0.0959  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [2310/4489]  eta: 2:14:04  lr: 0.000210  loss: 0.1107 (0.1939)  loss_classifier: 0.0223 (0.0371)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0069)  loss_rpn_box_reg: 0.0821 (0.1488)  time: 3.8629  data: 0.0967  max mem: 2501\n",
      "Epoch: [0]  [2320/4489]  eta: 2:13:29  lr: 0.000210  loss: 0.1180 (0.1937)  loss_classifier: 0.0223 (0.0370)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0005 (0.0069)  loss_rpn_box_reg: 0.0898 (0.1486)  time: 3.8616  data: 0.0945  max mem: 2501\n",
      "Epoch: [0]  [2330/4489]  eta: 2:12:53  lr: 0.000210  loss: 0.1180 (0.1934)  loss_classifier: 0.0232 (0.0370)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0005 (0.0069)  loss_rpn_box_reg: 0.0945 (0.1484)  time: 3.8603  data: 0.0923  max mem: 2501\n",
      "Epoch: [0]  [2340/4489]  eta: 2:12:18  lr: 0.000210  loss: 0.1152 (0.1932)  loss_classifier: 0.0215 (0.0369)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0069)  loss_rpn_box_reg: 0.0889 (0.1482)  time: 3.8643  data: 0.0918  max mem: 2501\n",
      "Epoch: [0]  [2350/4489]  eta: 2:11:43  lr: 0.000210  loss: 0.1526 (0.1930)  loss_classifier: 0.0215 (0.0369)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0006 (0.0068)  loss_rpn_box_reg: 0.1275 (0.1481)  time: 3.8728  data: 0.0961  max mem: 2501\n",
      "Epoch: [0]  [2360/4489]  eta: 2:11:07  lr: 0.000210  loss: 0.1536 (0.1928)  loss_classifier: 0.0263 (0.0368)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0006 (0.0068)  loss_rpn_box_reg: 0.1307 (0.1480)  time: 3.8680  data: 0.0964  max mem: 2501\n",
      "Epoch: [0]  [2370/4489]  eta: 2:10:32  lr: 0.000210  loss: 0.1216 (0.1924)  loss_classifier: 0.0236 (0.0368)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0068)  loss_rpn_box_reg: 0.0959 (0.1477)  time: 3.8599  data: 0.0928  max mem: 2501\n",
      "Epoch: [0]  [2380/4489]  eta: 2:09:56  lr: 0.000210  loss: 0.1131 (0.1921)  loss_classifier: 0.0226 (0.0368)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0068)  loss_rpn_box_reg: 0.0789 (0.1474)  time: 3.8741  data: 0.0946  max mem: 2501\n",
      "Epoch: [0]  [2390/4489]  eta: 2:09:21  lr: 0.000210  loss: 0.1115 (0.1917)  loss_classifier: 0.0245 (0.0367)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0068)  loss_rpn_box_reg: 0.0824 (0.1471)  time: 3.8768  data: 0.0971  max mem: 2501\n",
      "Epoch: [0]  [2400/4489]  eta: 2:08:45  lr: 0.000210  loss: 0.1163 (0.1915)  loss_classifier: 0.0230 (0.0366)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0067)  loss_rpn_box_reg: 0.0926 (0.1470)  time: 3.8654  data: 0.0939  max mem: 2501\n",
      "Epoch: [0]  [2410/4489]  eta: 2:08:10  lr: 0.000210  loss: 0.1318 (0.1913)  loss_classifier: 0.0226 (0.0366)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0010 (0.0067)  loss_rpn_box_reg: 0.1044 (0.1468)  time: 3.8900  data: 0.0949  max mem: 2501\n",
      "Epoch: [0]  [2420/4489]  eta: 2:07:35  lr: 0.000210  loss: 0.1118 (0.1910)  loss_classifier: 0.0234 (0.0366)  loss_box_reg: 0.0004 (0.0011)  loss_objectness: 0.0008 (0.0067)  loss_rpn_box_reg: 0.0860 (0.1467)  time: 3.8931  data: 0.0977  max mem: 2501\n",
      "Epoch: [0]  [2430/4489]  eta: 2:06:59  lr: 0.000210  loss: 0.1128 (0.1907)  loss_classifier: 0.0213 (0.0365)  loss_box_reg: 0.0003 (0.0011)  loss_objectness: 0.0003 (0.0067)  loss_rpn_box_reg: 0.0772 (0.1464)  time: 3.8647  data: 0.0944  max mem: 2501\n",
      "Epoch: [0]  [2440/4489]  eta: 2:06:33  lr: 0.000210  loss: 0.1196 (0.1904)  loss_classifier: 0.0241 (0.0365)  loss_box_reg: 0.0003 (0.0011)  loss_objectness: 0.0003 (0.0066)  loss_rpn_box_reg: 0.0879 (0.1462)  time: 4.4163  data: 0.0955  max mem: 2501\n",
      "Epoch: [0]  [2450/4489]  eta: 2:05:57  lr: 0.000210  loss: 0.1164 (0.1901)  loss_classifier: 0.0241 (0.0364)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0004 (0.0066)  loss_rpn_box_reg: 0.0787 (0.1459)  time: 4.4167  data: 0.0954  max mem: 2501\n",
      "Epoch: [0]  [2460/4489]  eta: 2:05:21  lr: 0.000210  loss: 0.1132 (0.1898)  loss_classifier: 0.0232 (0.0364)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0003 (0.0066)  loss_rpn_box_reg: 0.0787 (0.1457)  time: 3.8639  data: 0.0939  max mem: 2501\n",
      "Epoch: [0]  [2470/4489]  eta: 2:04:45  lr: 0.000210  loss: 0.1080 (0.1895)  loss_classifier: 0.0232 (0.0363)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0002 (0.0066)  loss_rpn_box_reg: 0.0838 (0.1454)  time: 3.8601  data: 0.0932  max mem: 2501\n",
      "Epoch: [0]  [2480/4489]  eta: 2:04:10  lr: 0.000210  loss: 0.1080 (0.1892)  loss_classifier: 0.0230 (0.0363)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0004 (0.0066)  loss_rpn_box_reg: 0.0821 (0.1452)  time: 3.8670  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [2490/4489]  eta: 2:03:34  lr: 0.000210  loss: 0.1130 (0.1889)  loss_classifier: 0.0221 (0.0362)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0065)  loss_rpn_box_reg: 0.0870 (0.1451)  time: 3.8717  data: 0.0964  max mem: 2501\n",
      "Epoch: [0]  [2500/4489]  eta: 2:02:58  lr: 0.000210  loss: 0.1459 (0.1888)  loss_classifier: 0.0224 (0.0362)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0006 (0.0065)  loss_rpn_box_reg: 0.1146 (0.1450)  time: 3.8647  data: 0.0952  max mem: 2501\n",
      "Epoch: [0]  [2510/4489]  eta: 2:02:22  lr: 0.000210  loss: 0.1402 (0.1886)  loss_classifier: 0.0213 (0.0361)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0065)  loss_rpn_box_reg: 0.1055 (0.1449)  time: 3.8622  data: 0.0960  max mem: 2501\n",
      "Epoch: [0]  [2520/4489]  eta: 2:01:46  lr: 0.000210  loss: 0.1103 (0.1883)  loss_classifier: 0.0192 (0.0361)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0003 (0.0065)  loss_rpn_box_reg: 0.0838 (0.1447)  time: 3.8586  data: 0.0957  max mem: 2501\n",
      "Epoch: [0]  [2530/4489]  eta: 2:01:10  lr: 0.000210  loss: 0.1179 (0.1882)  loss_classifier: 0.0193 (0.0360)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0002 (0.0064)  loss_rpn_box_reg: 0.1037 (0.1446)  time: 3.8562  data: 0.0949  max mem: 2501\n",
      "Epoch: [0]  [2540/4489]  eta: 2:00:34  lr: 0.000210  loss: 0.1377 (0.1880)  loss_classifier: 0.0245 (0.0360)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0004 (0.0064)  loss_rpn_box_reg: 0.1062 (0.1445)  time: 3.8569  data: 0.0928  max mem: 2501\n",
      "Epoch: [0]  [2550/4489]  eta: 1:59:58  lr: 0.000210  loss: 0.1414 (0.1879)  loss_classifier: 0.0225 (0.0360)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0003 (0.0064)  loss_rpn_box_reg: 0.1141 (0.1445)  time: 3.8601  data: 0.0938  max mem: 2501\n",
      "Epoch: [0]  [2560/4489]  eta: 1:59:22  lr: 0.000210  loss: 0.1331 (0.1876)  loss_classifier: 0.0235 (0.0359)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0004 (0.0064)  loss_rpn_box_reg: 0.1101 (0.1442)  time: 3.8606  data: 0.0943  max mem: 2501\n",
      "Epoch: [0]  [2570/4489]  eta: 1:58:46  lr: 0.000210  loss: 0.1188 (0.1874)  loss_classifier: 0.0261 (0.0359)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0064)  loss_rpn_box_reg: 0.0962 (0.1441)  time: 3.8568  data: 0.0924  max mem: 2501\n",
      "Epoch: [0]  [2580/4489]  eta: 1:58:10  lr: 0.000210  loss: 0.1110 (0.1871)  loss_classifier: 0.0232 (0.0358)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0004 (0.0063)  loss_rpn_box_reg: 0.0904 (0.1438)  time: 3.8585  data: 0.0933  max mem: 2501\n",
      "Epoch: [0]  [2590/4489]  eta: 1:57:34  lr: 0.000210  loss: 0.1009 (0.1868)  loss_classifier: 0.0186 (0.0358)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0003 (0.0063)  loss_rpn_box_reg: 0.0849 (0.1436)  time: 3.8585  data: 0.0941  max mem: 2501\n",
      "Epoch: [0]  [2600/4489]  eta: 1:56:58  lr: 0.000210  loss: 0.1147 (0.1865)  loss_classifier: 0.0204 (0.0357)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0063)  loss_rpn_box_reg: 0.0863 (0.1434)  time: 3.8559  data: 0.0924  max mem: 2501\n",
      "Epoch: [0]  [2610/4489]  eta: 1:56:22  lr: 0.000210  loss: 0.1152 (0.1863)  loss_classifier: 0.0215 (0.0357)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0005 (0.0063)  loss_rpn_box_reg: 0.0934 (0.1433)  time: 3.8551  data: 0.0908  max mem: 2501\n",
      "Epoch: [0]  [2620/4489]  eta: 1:55:46  lr: 0.000210  loss: 0.1200 (0.1860)  loss_classifier: 0.0215 (0.0356)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0004 (0.0062)  loss_rpn_box_reg: 0.0947 (0.1431)  time: 3.8574  data: 0.0924  max mem: 2501\n",
      "Epoch: [0]  [2630/4489]  eta: 1:55:09  lr: 0.000210  loss: 0.1061 (0.1857)  loss_classifier: 0.0213 (0.0356)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0004 (0.0062)  loss_rpn_box_reg: 0.0849 (0.1428)  time: 3.8610  data: 0.0954  max mem: 2501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [2640/4489]  eta: 1:54:33  lr: 0.000210  loss: 0.1080 (0.1855)  loss_classifier: 0.0227 (0.0355)  loss_box_reg: 0.0001 (0.0011)  loss_objectness: 0.0003 (0.0062)  loss_rpn_box_reg: 0.0849 (0.1427)  time: 3.8611  data: 0.0968  max mem: 2501\n",
      "Epoch: [0]  [2650/4489]  eta: 1:53:57  lr: 0.000210  loss: 0.1206 (0.1853)  loss_classifier: 0.0252 (0.0355)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0005 (0.0062)  loss_rpn_box_reg: 0.0881 (0.1425)  time: 3.8600  data: 0.0969  max mem: 2501\n",
      "Epoch: [0]  [2660/4489]  eta: 1:53:21  lr: 0.000210  loss: 0.1011 (0.1850)  loss_classifier: 0.0254 (0.0355)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0006 (0.0062)  loss_rpn_box_reg: 0.0788 (0.1423)  time: 3.8576  data: 0.0979  max mem: 2501\n",
      "Epoch: [0]  [2670/4489]  eta: 1:52:52  lr: 0.000210  loss: 0.0968 (0.1847)  loss_classifier: 0.0195 (0.0354)  loss_box_reg: 0.0002 (0.0011)  loss_objectness: 0.0007 (0.0062)  loss_rpn_box_reg: 0.0753 (0.1420)  time: 4.4018  data: 0.0989  max mem: 2501\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20736\\2332459263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# train for one epoch, printing every 10 iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# update the learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Freelancing\\On-Going\\MLMar\\engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mloss_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[operator]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torchvision\\models\\detection\\rpn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, features, targets)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mobjectness\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_bbox_deltas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mnum_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, image_list, feature_maps)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             ]\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrid_sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         ]\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\marml\\lib\\site-packages\\torchvision\\models\\detection\\anchor_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             ]\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrid_sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         ]\n\u001b[0;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_cell_anchors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# let's train it for 10 epochs\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6mYGFLxkO8F"
   },
   "source": [
    "Now that training has finished, let's have a look at what it actually predicts in a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHwIdxH76uPj"
   },
   "outputs": [],
   "source": [
    "# pick one image from the test set\n",
    "img, _ = dataset_test[0]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(device)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmN602iKsuey"
   },
   "source": [
    "Printing the prediction shows that we have a list of dictionaries. Each element of the list corresponds to a different image. As we have a single image, there is a single dictionary in the list.\n",
    "The dictionary contains the predictions for the image we passed. In this case, we can see that it contains `boxes`, `labels`, `masks` and `scores` as fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lkmb3qUu6zw3",
    "outputId": "4b070498-af59-48a6-e901-ccacb184fa69"
   },
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwT21rzotFbH"
   },
   "source": [
    "Let's inspect the image and the predicted segmentation masks.\n",
    "\n",
    "For that, we need to convert the image, which has been rescaled to 0-1 and had the channels flipped so that we have it in `[C, H, W]` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "bpqN9t1u7B2J",
    "outputId": "c7787fe3-2173-4440-aebb-9a826938581e"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M58J3O9OtT1G"
   },
   "source": [
    "And let's now visualize the top predicted segmentation mask. The masks are predicted as `[N, 1, H, W]`, where `N` is the number of predictions, and are probability maps between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "5v5S3bm07SO1",
    "outputId": "242f9951-972d-4110-c963-57acfd1b1897"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['masks'][0, 0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EZCVtCPunrT"
   },
   "source": [
    "Looks pretty good!\n",
    "\n",
    "## Wrapping up\n",
    "\n",
    "In this tutorial, you have learned how to create your own training pipeline for instance segmentation models, on a custom dataset.\n",
    "For that, you wrote a `torch.utils.data.Dataset` class that returns the images and the ground truth boxes and segmentation masks. You also leveraged a Mask R-CNN model pre-trained on COCO train2017 in order to perform transfer learning on this new dataset.\n",
    "\n",
    "For a more complete example, which includes multi-machine / multi-gpu training, check `references/detection/train.py`, which is present in the [torchvision GitHub repo](https://github.com/pytorch/vision/tree/v0.8.2/references/detection). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "torchvision_finetuning_instance_segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1135b1ce2cd546469cf17372f4e54d0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11ef8a23d72b4d07a96eb606a8fa7d2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_681f345b760e498ab2dfc5fcf07ec6e3",
       "IPY_MODEL_c46939cc3d464b72827c194b2e01e85f",
       "IPY_MODEL_a660849e2de94da3ac03810cdece69b7"
      ],
      "layout": "IPY_MODEL_a1c7b3c5d9084c659634d577dc56dcc2"
     }
    },
    "185aeb8e45074993bff2dfe7ec7fddd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "234b27f5e6374a62a8686fe7d32fddf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36db4a67e2464098bcb5b3dd3a54b843": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37c6d9f45f9d441895ed8610b3b5742b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dd5d7a58a9d4b15817aeee7d13a79f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4308ed7944ee4ef596b4ebfbc3a3213b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "493adee22cb74a8a96183c9db4c5c56c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a33eeab89ffd48ddb69854bb4dbd88d8",
      "placeholder": "​",
      "style": "IPY_MODEL_37c6d9f45f9d441895ed8610b3b5742b",
      "value": "100%"
     }
    },
    "4d28be85396240e0ac7c45b7d6ae06d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_493adee22cb74a8a96183c9db4c5c56c",
       "IPY_MODEL_eb4c4da938104534901663544b792d29",
       "IPY_MODEL_dbd1290d275f4a21a01bc3a1643ea43a"
      ],
      "layout": "IPY_MODEL_59d43ab0fe5c4fb3a87697219545cc15"
     }
    },
    "59d43ab0fe5c4fb3a87697219545cc15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "681f345b760e498ab2dfc5fcf07ec6e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bceb871ca384508bc40bbbbda78a2b0",
      "placeholder": "​",
      "style": "IPY_MODEL_3dd5d7a58a9d4b15817aeee7d13a79f9",
      "value": "100%"
     }
    },
    "74e7d3cdc9a24f0ca3684250da665f34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bceb871ca384508bc40bbbbda78a2b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1c7b3c5d9084c659634d577dc56dcc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a33eeab89ffd48ddb69854bb4dbd88d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a660849e2de94da3ac03810cdece69b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_234b27f5e6374a62a8686fe7d32fddf7",
      "placeholder": "​",
      "style": "IPY_MODEL_74e7d3cdc9a24f0ca3684250da665f34",
      "value": " 160M/160M [00:00&lt;00:00, 231MB/s]"
     }
    },
    "afe2458d0b5a4cf49c46c4b462a84fe9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c46939cc3d464b72827c194b2e01e85f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1d6e629955149b7b07c1c20460c205c",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4308ed7944ee4ef596b4ebfbc3a3213b",
      "value": 167502836
     }
    },
    "dbd1290d275f4a21a01bc3a1643ea43a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_185aeb8e45074993bff2dfe7ec7fddd8",
      "placeholder": "​",
      "style": "IPY_MODEL_1135b1ce2cd546469cf17372f4e54d0e",
      "value": " 170M/170M [00:02&lt;00:00, 59.5MB/s]"
     }
    },
    "e1d6e629955149b7b07c1c20460c205c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb4c4da938104534901663544b792d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36db4a67e2464098bcb5b3dd3a54b843",
      "max": 178090079,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afe2458d0b5a4cf49c46c4b462a84fe9",
      "value": 178090079
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
